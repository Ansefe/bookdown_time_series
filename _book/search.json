[{"path":"index.html","id":"justificaci√≥n-de-elecci√≥n-del-dataset","chapter":"1 Justificaci√≥n de elecci√≥n del Dataset","heading":"1 Justificaci√≥n de elecci√≥n del Dataset","text":"Integrantes:\nHarvey Bastidas, Alexander Alvarado y Andr√©s CaicedoMateria:\nAn√°lisis de series de tiempoProfesora:\nIsabel Cristina Garc√≠a","code":""},{"path":"index.html","id":"informaci√≥n-del-dataset","chapter":"1 Justificaci√≥n de elecci√≥n del Dataset","heading":"1.1 Informaci√≥n del Dataset","text":"El dataset seleccionado para este an√°lisis es el siguiente: EUR/USD Forex Trading Data (2003-2021), el cual fue extra√≠do de Forex Trading Charts, propiedad de Barchart Solutions, una empresa especializada en servicios financieros en los Estados Unidos. Barchart Solutions cuenta con reconocidos clientes como el Banco Goldman Sachs y el Bank Canada, lo que nos lleva concluir que los datos ofrecidos son confiables y precisos para realizar an√°lisis financieros.La empresa matriz, Barchart Solutions, tiene su sede en:222 S. Riverside Plaza, Suite 810,\nChicago, IL 60606, Estados UnidosEl dataset presenta las tasas de cambio del par de divisas EUR/USD desde el 5 de mayo de 2003 hasta el 16 de octubre de 2021, con una periodicidad de 4 horas. Este conjunto de datos incluye las siguientes 6 columnas:Open: Precio de apertura para el periodo.High: Precio m√°ximo durante el periodo.Low: Precio m√≠nimo durante el periodo.Close: Precio de cierre para el periodo.Volume: Volumen de transacciones reportado.Es importante resaltar que los datos contienen valores nulos ni perdidos para los d√≠as de semana, aunque se registran valores durante los fines de semana, lo que es normal en los mercados de Forex.El an√°lisis se centrar√° en la columna Close, que representa el precio de cierre, dado que es la variable m√°s relevante para el pron√≥stico de tendencias.","code":""},{"path":"index.html","id":"justificaci√≥n-de-la-elecci√≥n-del-dataset","chapter":"1 Justificaci√≥n de elecci√≥n del Dataset","heading":"1.2 Justificaci√≥n de la Elecci√≥n del Dataset","text":"La elecci√≥n de este dataset se fundamenta en la importancia de analizar la tasa de cambio EUR/USD, uno de los pares de divisas m√°s negociados en el mercado Forex. La predicci√≥n de la tendencia de la tasa de cambio es crucial para varias estrategias financieras, como el balanceo de portafolios de inversi√≥n. En este contexto, se pueden usar tanto la Teor√≠a Moderna de Portafolios (MPT) como la Teor√≠a de Portafolios Post-Moderna (PMPT), que son ampliamente utilizadas en la optimizaci√≥n de la distribuci√≥n de activos. Ambas teor√≠as se benefician de predicciones precisas de la tendencia de los activos subyacentes, como es el caso de las divisas.Adem√°s, este dataset ofrece una excelente relaci√≥n se√±al-ruido, lo que mejora la predictibilidad de los modelos basados en series de tiempo. Utilizamos el coeficiente de variaci√≥n (CV) como criterio para seleccionar este dataset, debido que es una m√©trica robusta para medir la variabilidad en relaci√≥n con la media. Un CV bajo indica que la variabilidad en los datos es relativamente baja, lo que es favorable para la predicci√≥n de tendencias.El coeficiente de variaci√≥n calculado para la columna ‚ÄúClose‚Äù de este dataset es de aproximadamente 9.5%, lo que lo convierte en el m√°s bajo entre los datasets que evaluamos. Esto lo hace ideal para el pron√≥stico, ya que un CV bajo sugiere que la se√±al en los datos es fuerte en comparaci√≥n con el ruido.","code":""},{"path":"index.html","id":"relaci√≥n-con-el-signal-to-noise-ratio-snr","chapter":"1 Justificaci√≥n de elecci√≥n del Dataset","heading":"1.2.1 Relaci√≥n con el Signal-to-Noise Ratio (SNR)","text":"El coeficiente de variaci√≥n (CV) est√° inversamente relacionado con el Signal--Noise Ratio (SNR), una m√©trica com√∫nmente utilizada en el procesamiento de se√±ales. El SNR mide la proporci√≥n de la potencia de la se√±al con respecto la del ruido, lo que ayuda evaluar la calidad de los datos.El SNR para este dataset se calcula como el cuadrado del inverso del CV. Para el EUR/USD, con un CV de 0.09, el SNR es aproximadamente:\\[\nSNR = \\left(\\frac{1}{0.09}\\right)^2 \\approx 123\n\\]Este valor indica que la se√±al es mucho m√°s fuerte que el ruido en este dataset. En contraste, otro dataset que probamos, con un CV de 20%, ten√≠a un SNR mucho menor, alrededor de 25. La diferencia muestra que el dataset de EUR/USD tiene una mayor preponderancia de se√±al sobre el ruido, lo que permite una mejor predictibilidad en los modelos de pron√≥stico.Dado que sabemos que el SNR es aprox 123, esto significa que el ruido es aprox 1/123 = 0.008 que nos da una idea del m√°ximo error absoluto (MAE) en los datos Normalizados en el pron√≥sitco del siguiente periodo que podemos obtener, ya que errores por debajo de este valor probablemente incluir√≠an la predicci√≥n del ruido y podr√≠an ser indicador de overfitting en el modelo predictivo usado.","code":""},{"path":"index.html","id":"importancia-de-analizar-este-dataset","chapter":"1 Justificaci√≥n de elecci√≥n del Dataset","heading":"1.3 Importancia de Analizar este Dataset","text":"La capacidad de predecir con precisi√≥n la tasa de cambio EUR/USD tiene m√∫ltiples aplicaciones en el sector financiero. En primer lugar, es fundamental para el trading de divisas (Forex), donde una mejor predicci√≥n de las tendencias puede resultar en decisiones de inversi√≥n m√°s acertadas. Adem√°s, es esencial para la gesti√≥n de portafolios financieros, ya que permite el uso de herramientas como la Teor√≠a Moderna de Portafolios (MPT), donde la diversificaci√≥n se realiza teniendo en cuenta tanto la tendencia como la variabilidad de los activos.Por lo tanto, este dataset fue seleccionado debido su alta calidad y baja variabilidad, lo que lo hace ideal para el an√°lisis predictivo en el mercado de Forex, as√≠ como en la gesti√≥n de portafolios. El alto SNR nos da confianza en que las predicciones basadas en este dataset ser√°n precisas y √∫tiles en un entorno real, al mismo tiempo que nos alerta sobre los l√≠mites predictivos en funci√≥n del ruido presente en los datos.","code":""},{"path":"intro.html","id":"intro","chapter":"2 Estructura de los datos","heading":"2 Estructura de los datos","text":"Con el prop√≥sito de observar las tendencias y cambios estructurales en la serie, se realizan pruebas estad√≠sticas para conocer la estructura subyacente de la serie.","code":""},{"path":"intro.html","id":"c√°lculo-de-medias-m√≥viles-simples","chapter":"2 Estructura de los datos","heading":"2.1 C√°lculo de Medias M√≥viles Simples:","text":"El c√°lculo de medias m√≥viles es una t√©cnica com√∫n en el an√°lisis de series de tiempo utilizada para suavizar las fluctuaciones corto plazo y destacar las tendencias subyacentes en los datos. En este an√°lisis, se implementan medias m√≥viles de corto y largo plazo para identificar patrones de comportamiento y ayudar en la toma de decisiones basadas en tendencias m√°s claras.Media m√≥vil de 50 periodos (MA corta):\nSigue de cerca las fluctuaciones del precio de cierre, respondiendo r√°pidamente los cambios de tendencia.\nCaptura las tendencias corto plazo, pero tambi√©n refleja mucha volatilidad.\nMedia m√≥vil de 50 periodos (MA corta):Sigue de cerca las fluctuaciones del precio de cierre, respondiendo r√°pidamente los cambios de tendencia.Sigue de cerca las fluctuaciones del precio de cierre, respondiendo r√°pidamente los cambios de tendencia.Captura las tendencias corto plazo, pero tambi√©n refleja mucha volatilidad.Captura las tendencias corto plazo, pero tambi√©n refleja mucha volatilidad.Media m√≥vil de 500 periodos (MA larga):\nSe mueve de forma m√°s suave, reaccionando m√°s lentamente los cambios de precios.\nIndica la tendencia largo plazo, proporcionando una visi√≥n m√°s estable del comportamiento del mercado.\nMedia m√≥vil de 500 periodos (MA larga):Se mueve de forma m√°s suave, reaccionando m√°s lentamente los cambios de precios.Se mueve de forma m√°s suave, reaccionando m√°s lentamente los cambios de precios.Indica la tendencia largo plazo, proporcionando una visi√≥n m√°s estable del comportamiento del mercado.Indica la tendencia largo plazo, proporcionando una visi√≥n m√°s estable del comportamiento del mercado.","code":""},{"path":"intro.html","id":"an√°lisis-de-rezagos","chapter":"2 Estructura de los datos","heading":"2.2 An√°lisis de Rezagos","text":"C√≥mo se comporta la serie de tiempo con respecto sus valores pasados, introduciendo rezagos.En cada uno de los gr√°ficos, los puntos siguen una l√≠nea casi perfectamente recta, sugiriendo una alta autocorrelaci√≥n entre los valores de la serie con sus rezagos cercanos.La pendiente positiva indica que cuando el valor anterior era alto, el valor actual tambi√©n tiende ser alto, y lo mismo sucede para valores bajos. Esto sugiere que la serie es muy persistente, es decir, los precios tienden seguir una direcci√≥n similar en el corto plazo.Dado que hay patrones dispersos o sin forma definida, se puede inferir que la serie tiene cambios abruptos o comportamiento ca√≥tico entre los puntos cercanos. Esto podr√≠a indicar que hay mucha volatilidad en los intervalos de 4 horas.","code":""},{"path":"intro.html","id":"an√°lisis-de-estacionalidad","chapter":"2 Estructura de los datos","heading":"2.3 An√°lisis de Estacionalidad","text":"Para detectar si existe estacionalidad (patrones repetitivos), utilizaremos decomposici√≥n o test de estacionalidad.En la gr√°fica de descomposici√≥n de series de tiempo se visualizan los componentes de la serie: datos originales, estacionalidad, tendencia y residuales (remainder):1. Datos Originales (data): En la primera gr√°fica (data), se observan los valores de cierre lo largo del tiempo. Vemos fluctuaciones en los precios con algunas subidas y bajadas claras, lo que indica la volatilidad normal del mercado Forex.2. Componente Estacional (seasonal): El segundo gr√°fico muestra un patr√≥n repetitivo y peri√≥dico. Este patr√≥n sugiere que hay ciclos regulares en la serie. La estacionalidad se mantiene constante lo largo del tiempo, lo que indica que ciertos movimientos en el mercado se repiten con una periodicidad fija (en este caso, podr√≠a ser diaria o semanal). Es probable que este componente estacional refleje la actividad c√≠clica en horarios espec√≠ficos o d√≠as determinados, como mayor volatilidad durante sesiones overlap (como entre Londres y Nueva York).3. Componente de Tendencia (trend): El tercer gr√°fico muestra una tendencia suavizada que sigue la direcci√≥n general del mercado. Observamos fases de alzas y ca√≠das: primero hay una subida clara, luego una ca√≠da, y finalmente otra leve tendencia hacia la estabilidad.4. Componente de Residuos o Resto (remainder): El √∫ltimo gr√°fico (remainder) muestra los residuos o la parte de los datos que es explicada por la tendencia ni la estacionalidad. Estos residuos parecen ser ruido blanco, con fluctuaciones alrededor de cero, lo que indica que hay patrones significativos adicionales capturados por los otros componentes.","code":""},{"path":"preprocesamiento-y-visualizaci√≥n.html","id":"preprocesamiento-y-visualizaci√≥n","chapter":"3 Preprocesamiento y Visualizaci√≥n","heading":"3 Preprocesamiento y Visualizaci√≥n","text":"En este an√°lisis, trabajaremos con el dataset de tipo de cambio EUR/USD de Forex proporcionado, el cual incluye datos hist√≥ricos de 2003 2021. El objetivo es estudiar las tendencias, estacionalidad y comportamiento estructural de la serie de tiempo. Adem√°s, evaluaremos si es necesario realizar transformaciones en la serie para estabilizar la varianza y facilitar la predicci√≥n.","code":""},{"path":"preprocesamiento-y-visualizaci√≥n.html","id":"descomposici√≥n-de-la-serie-de-tiempo","chapter":"3 Preprocesamiento y Visualizaci√≥n","heading":"3.1 Descomposici√≥n de la Serie de Tiempo","text":"En esta etapa se busca realizar la descomposici√≥n de la serie de tiempo para identificar los componentes de tendencia, estacionalidad y residuos.En la gr√°fica de descomposici√≥n de series de tiempo se visualizan los componentes de la serie: datos originales, estacionalidad, tendencia y residuales (remainder):1. Datos Originales (data): En la primera gr√°fica (data), se observan los valores de cierre lo largo del tiempo. Vemos fluctuaciones en los precios con algunas subidas y bajadas claras, lo que indica la volatilidad normal del mercado Forex.2. Componente Estacional (seasonal): El segundo gr√°fico muestra un patr√≥n repetitivo y peri√≥dico. Este patr√≥n sugiere que hay ciclos regulares en la serie. La estacionalidad se mantiene constante lo largo del tiempo, lo que indica que ciertos movimientos en el mercado se repiten con una periodicidad fija (en este caso, podr√≠a ser diaria o semanal). Es probable que este componente estacional refleje la actividad c√≠clica en horarios espec√≠ficos o d√≠as determinados, como mayor volatilidad durante sesiones overlap (como entre Londres y Nueva York).3. Componente de Tendencia (trend): El tercer gr√°fico muestra una tendencia suavizada que sigue la direcci√≥n general del mercado. Observamos fases de alzas y ca√≠das: primero hay una subida clara, luego una ca√≠da, y finalmente otra leve tendencia hacia la estabilidad.4. Componente de Residuos o Resto (remainder): El √∫ltimo gr√°fico (remainder) muestra los residuos o la parte de los datos que es explicada por la tendencia ni la estacionalidad. Estos residuos parecen ser ruido blanco, con fluctuaciones alrededor de cero, lo que indica que hay patrones significativos adicionales capturados por los otros componentes.","code":""},{"path":"preprocesamiento-y-visualizaci√≥n.html","id":"prueba-de-estacionariedad","chapter":"3 Preprocesamiento y Visualizaci√≥n","heading":"3.2 Prueba de Estacionariedad","text":"La estacionariedad es importante en el an√°lisis de series de tiempo porque indica si las propiedades estad√≠sticas de la serie (como la media y la varianza) se mantienen constantes lo largo del tiempo. Una serie estacionaria es generalmente m√°s f√°cil de modelar y predecir.La interpretaci√≥n es la siguiente:Hip√≥tesis nula (H0): La serie es estacionaria (tiene una ra√≠z unitaria).Hip√≥tesis nula (H0): La serie es estacionaria (tiene una ra√≠z unitaria).Hip√≥tesis alternativa (H1): La serie es estacionaria.Hip√≥tesis alternativa (H1): La serie es estacionaria.En todas las configuraciones (sin tendencia ni drift, con drift, y con drift y tendencia), los p-valores son mayores 0.05. Esto implica que, bajo ninguna de estas configuraciones, la serie es estacionaria en su forma actual.","code":"## Augmented Dickey-Fuller Test \n## alternative: stationary \n##  \n## Type 1: no drift no trend \n##       lag    ADF p.value\n##  [1,]   0 -0.135   0.606\n##  [2,]   1 -0.133   0.606\n##  [3,]   2 -0.135   0.606\n##  [4,]   3 -0.131   0.607\n##  [5,]   4 -0.143   0.603\n##  [6,]   5 -0.146   0.603\n##  [7,]   6 -0.149   0.602\n##  [8,]   7 -0.147   0.602\n##  [9,]   8 -0.155   0.600\n## [10,]   9 -0.156   0.600\n## [11,]  10 -0.158   0.599\n## [12,]  11 -0.174   0.594\n## [13,]  12 -0.172   0.595\n## [14,]  13 -0.169   0.596\n## [15,]  14 -0.166   0.597\n## Type 2: with drift no trend \n##       lag   ADF p.value\n##  [1,]   0 -2.20   0.248\n##  [2,]   1 -2.21   0.244\n##  [3,]   2 -2.23   0.238\n##  [4,]   3 -2.19   0.253\n##  [5,]   4 -2.20   0.250\n##  [6,]   5 -2.20   0.248\n##  [7,]   6 -2.21   0.244\n##  [8,]   7 -2.20   0.248\n##  [9,]   8 -2.19   0.254\n## [10,]   9 -2.18   0.257\n## [11,]  10 -2.18   0.255\n## [12,]  11 -2.18   0.257\n## [13,]  12 -2.18   0.257\n## [14,]  13 -2.16   0.263\n## [15,]  14 -2.17   0.258\n## Type 3: with drift and trend \n##       lag   ADF p.value\n##  [1,]   0 -2.91   0.192\n##  [2,]   1 -2.93   0.186\n##  [3,]   2 -2.94   0.180\n##  [4,]   3 -2.90   0.196\n##  [5,]   4 -2.90   0.197\n##  [6,]   5 -2.90   0.196\n##  [7,]   6 -2.91   0.193\n##  [8,]   7 -2.90   0.197\n##  [9,]   8 -2.88   0.207\n## [10,]   9 -2.87   0.210\n## [11,]  10 -2.87   0.209\n## [12,]  11 -2.85   0.219\n## [13,]  12 -2.85   0.218\n## [14,]  13 -2.84   0.223\n## [15,]  14 -2.85   0.216\n## ---- \n## Note: in fact, p.value = 0.01 means p.value <= 0.01## $type1\n##       lag        ADF   p.value\n##  [1,]   0 -0.1349353 0.6056581\n##  [2,]   1 -0.1332845 0.6061322\n##  [3,]   2 -0.1350012 0.6056392\n##  [4,]   3 -0.1311022 0.6067589\n##  [5,]   4 -0.1432485 0.6032707\n##  [6,]   5 -0.1455745 0.6026027\n##  [7,]   6 -0.1491280 0.6015823\n##  [8,]   7 -0.1466525 0.6022932\n##  [9,]   8 -0.1553530 0.5997946\n## [10,]   9 -0.1558747 0.5996447\n## [11,]  10 -0.1575228 0.5991714\n## [12,]  11 -0.1743717 0.5943327\n## [13,]  12 -0.1723248 0.5949206\n## [14,]  13 -0.1686293 0.5959819\n## [15,]  14 -0.1662663 0.5966605\n## \n## $type2\n##       lag       ADF   p.value\n##  [1,]   0 -2.199690 0.2481241\n##  [2,]   1 -2.210308 0.2438767\n##  [3,]   2 -2.225752 0.2376991\n##  [4,]   3 -2.186315 0.2534741\n##  [5,]   4 -2.196090 0.2495641\n##  [6,]   5 -2.199991 0.2480038\n##  [7,]   6 -2.210932 0.2436273\n##  [8,]   7 -2.199519 0.2481923\n##  [9,]   8 -2.185380 0.2538481\n## [10,]   9 -2.178336 0.2566657\n## [11,]  10 -2.183564 0.2545744\n## [12,]  11 -2.178602 0.2565592\n## [13,]  12 -2.178490 0.2566041\n## [14,]  13 -2.163515 0.2625942\n## [15,]  14 -2.174827 0.2580694\n## \n## $type3\n##       lag       ADF   p.value\n##  [1,]   0 -2.911720 0.1919072\n##  [2,]   1 -2.925278 0.1861988\n##  [3,]   2 -2.940306 0.1798712\n##  [4,]   3 -2.902268 0.1958871\n##  [5,]   4 -2.899542 0.1970351\n##  [6,]   5 -2.901407 0.1962497\n##  [7,]   6 -2.909540 0.1928254\n##  [8,]   7 -2.900196 0.1967594\n##  [9,]   8 -2.875536 0.2071427\n## [10,]   9 -2.867569 0.2104971\n## [11,]  10 -2.871608 0.2087965\n## [12,]  11 -2.848029 0.2187245\n## [13,]  12 -2.850350 0.2177475\n## [14,]  13 -2.838511 0.2227323\n## [15,]  14 -2.853430 0.2164506"},{"path":"preprocesamiento-y-visualizaci√≥n.html","id":"diferenciaci√≥n-para-estacionariedad","chapter":"3 Preprocesamiento y Visualizaci√≥n","heading":"3.3 Diferenciaci√≥n para Estacionariedad","text":"Como la serie es estacionaria, el siguiente paso es aplicar una diferenciaci√≥n para intentar volverla estacionaria. La diferenciaci√≥n ayuda eliminar tendencias y hacer que las propiedades estad√≠sticas de la serie se mantengan constantes lo largo del tiempo.Aplicaremos una diferenciaci√≥n de primer orden y realizaremos nuevamente la prueba ADF para verificar si la serie se ha vuelto estacionaria.Para este an√°lisis, utilizaremos la columna de cierre (Close) del dataset como nuestra serie de tiempo principal. Convertiremos los datos formato de serie temporal.Aplicaremos una primera diferenciaci√≥n.Despu√©s de la primera diferenciaci√≥n, se puede obtener que por cada tick qued√≥ el valor del return (x-x_ant) ue es el resultado de la aplicaci√≥n de la dirferenciaci√≥nd e primer orden. Como se aprecia, la serie ya tiene una tendencia sino que presenta un comportamiento estacionario, sinembargo, esta serie de tiempo parece ser menos predecible que la serie de tiempo antes de la diferenciaci√≥n, ya que evidentemente tiene mayor desviaci√≥n est√°ndar y por tanto un mayor Coeficiente de Variaci√≥n y un menor SNR.","code":""},{"path":"preprocesamiento-y-visualizaci√≥n.html","id":"verificaci√≥n-de-estacionariedad-en-la-serie-diferenciada","chapter":"3 Preprocesamiento y Visualizaci√≥n","heading":"3.4 Verificaci√≥n de Estacionariedad en la Serie Diferenciada","text":"Aplicamos nuevamente la prueba Dickey-Fuller la serie diferenciada para verificar si ahora es estacionaria.","code":"## Augmented Dickey-Fuller Test \n## alternative: stationary \n##  \n## Type 1: no drift no trend \n##       lag    ADF p.value\n##  [1,]   0 -169.3    0.01\n##  [2,]   1 -119.0    0.01\n##  [3,]   2  -99.3    0.01\n##  [4,]   3  -84.8    0.01\n##  [5,]   4  -75.7    0.01\n##  [6,]   5  -68.7    0.01\n##  [7,]   6  -64.1    0.01\n##  [8,]   7  -60.1    0.01\n##  [9,]   8  -56.8    0.01\n## [10,]   9  -53.7    0.01\n## [11,]  10  -50.9    0.01\n## [12,]  11  -48.8    0.01\n## [13,]  12  -47.3    0.01\n## [14,]  13  -45.4    0.01\n## [15,]  14  -43.7    0.01\n## Type 2: with drift no trend \n##       lag    ADF p.value\n##  [1,]   0 -169.3    0.01\n##  [2,]   1 -119.0    0.01\n##  [3,]   2  -99.3    0.01\n##  [4,]   3  -84.8    0.01\n##  [5,]   4  -75.7    0.01\n##  [6,]   5  -68.7    0.01\n##  [7,]   6  -64.1    0.01\n##  [8,]   7  -60.1    0.01\n##  [9,]   8  -56.8    0.01\n## [10,]   9  -53.7    0.01\n## [11,]  10  -50.9    0.01\n## [12,]  11  -48.8    0.01\n## [13,]  12  -47.3    0.01\n## [14,]  13  -45.4    0.01\n## [15,]  14  -43.7    0.01\n## Type 3: with drift and trend \n##       lag    ADF p.value\n##  [1,]   0 -169.3    0.01\n##  [2,]   1 -119.0    0.01\n##  [3,]   2  -99.3    0.01\n##  [4,]   3  -84.9    0.01\n##  [5,]   4  -75.7    0.01\n##  [6,]   5  -68.7    0.01\n##  [7,]   6  -64.1    0.01\n##  [8,]   7  -60.1    0.01\n##  [9,]   8  -56.8    0.01\n## [10,]   9  -53.7    0.01\n## [11,]  10  -50.9    0.01\n## [12,]  11  -48.8    0.01\n## [13,]  12  -47.3    0.01\n## [14,]  13  -45.4    0.01\n## [15,]  14  -43.7    0.01\n## ---- \n## Note: in fact, p.value = 0.01 means p.value <= 0.01## $type1\n##       lag        ADF p.value\n##  [1,]   0 -169.27722    0.01\n##  [2,]   1 -119.03874    0.01\n##  [3,]   2  -99.30334    0.01\n##  [4,]   3  -84.84969    0.01\n##  [5,]   4  -75.69590    0.01\n##  [6,]   5  -68.70703    0.01\n##  [7,]   6  -64.07591    0.01\n##  [8,]   7  -60.05652    0.01\n##  [9,]   8  -56.77621    0.01\n## [10,]   9  -53.68723    0.01\n## [11,]  10  -50.91061    0.01\n## [12,]  11  -48.81278    0.01\n## [13,]  12  -47.29027    0.01\n## [14,]  13  -45.38630    0.01\n## [15,]  14  -43.68676    0.01\n## \n## $type2\n##       lag        ADF p.value\n##  [1,]   0 -169.27433    0.01\n##  [2,]   1 -119.03671    0.01\n##  [3,]   2  -99.30166    0.01\n##  [4,]   3  -84.84825    0.01\n##  [5,]   4  -75.69462    0.01\n##  [6,]   5  -68.70587    0.01\n##  [7,]   6  -64.07484    0.01\n##  [8,]   7  -60.05550    0.01\n##  [9,]   8  -56.77525    0.01\n## [10,]   9  -53.68632    0.01\n## [11,]  10  -50.90973    0.01\n## [12,]  11  -48.81194    0.01\n## [13,]  12  -47.28946    0.01\n## [14,]  13  -45.38553    0.01\n## [15,]  14  -43.68601    0.01\n## \n## $type3\n##       lag        ADF p.value\n##  [1,]   0 -169.27489    0.01\n##  [2,]   1 -119.03832    0.01\n##  [3,]   2  -99.30402    0.01\n##  [4,]   3  -84.85094    0.01\n##  [5,]   4  -75.69772    0.01\n##  [6,]   5  -68.70929    0.01\n##  [7,]   6  -64.07866    0.01\n##  [8,]   7  -60.05942    0.01\n##  [9,]   8  -56.77944    0.01\n## [10,]   9  -53.69075    0.01\n## [11,]  10  -50.91391    0.01\n## [12,]  11  -48.81642    0.01\n## [13,]  12  -47.29426    0.01\n## [14,]  13  -45.39063    0.01\n## [15,]  14  -43.69120    0.01"},{"path":"preprocesamiento-y-visualizaci√≥n.html","id":"justificaci√≥n-de-la-transformaci√≥n","chapter":"3 Preprocesamiento y Visualizaci√≥n","heading":"3.5 Justificaci√≥n de la Transformaci√≥n","text":"Dado que la serie original era estacionaria, fue necesario aplicar una diferenciaci√≥n de primer orden para hacerla estacionaria. Esta transformaci√≥n es importante para poder aplicar modelos de series de tiempo que asumen estacionariedad y para obtener mejores resultados en el an√°lisis de patrones y predicciones.","code":""},{"path":"preprocesamiento-y-visualizaci√≥n.html","id":"an√°lisis-de-autocorrelaci√≥n","chapter":"3 Preprocesamiento y Visualizaci√≥n","heading":"3.6 An√°lisis de Autocorrelaci√≥n","text":"Graficaremos las funciones de autocorrelaci√≥n (ACF) y autocorrelaci√≥n parcial (PACF) para observar la dependencia temporal en los datos diferenciados.La ACF la izquierda muestra c√≥mo los valores actuales de la serie diferenciada est√°n correlacionados con sus valores en diferentes rezagos (lags). Algunos puntos de la ACF est√°n fuera de las l√≠neas de significancia (l√≠neas punteadas azules), lo cual sugiere que hay correlaciones significativas en esos rezagos espec√≠ficos. Este patr√≥n puede ser indicativo de que a√∫n existen estructuras autoregresivas o de medias m√≥viles en la serie, incluso despu√©s de la diferenciaci√≥n.La PACF la derecha muestra la autocorrelaci√≥n de la serie diferenciada en cada rezago eliminando el efecto de los rezagos intermedios. Similar la ACF, algunos valores est√°n fuera de las l√≠neas de significancia, lo que indica correlaci√≥n significativa en esos rezagos espec√≠ficos. Este patr√≥n puede sugerir la presencia de efectos autoregresivos en los rezagos correspondientes.Los picos significativos en la ACF y PACF sugieren que la serie diferenciada podr√≠a beneficiarse de un modelo ARIMA para capturar la estructura subyacente. Dependiendo de la cantidad de rezagos significativos en cada gr√°fico, podr√≠a ser apropiado un modelo ARIMA espec√≠fico (por ejemplo, con ciertos √≥rdenes autoregresivos y de medias m√≥viles).","code":"\n# Graficar ACF y PACF de la serie diferenciada\npar(mfrow = c(1, 2))\nAcf(forex_diff, main = \"ACF de la Serie Diferenciada\")\nPacf(forex_diff, main = \"PACF de la Serie Diferenciada\")\npar(mfrow = c(1,1))"},{"path":"preprocesamiento-y-visualizaci√≥n.html","id":"modelo-arima","chapter":"3 Preprocesamiento y Visualizaci√≥n","heading":"3.7 Modelo ARIMA","text":"Utilizaremos auto.arima para identificar el mejor modelo ARIMA para los datos.El modelo ajustado para la serie forex_diff es un ARIMA(0,0,0) con media cero, lo que sugiere que la serie presenta patrones autoregresivos ni de medias m√≥viles significativos, siendo esencialmente ruido blanco. El valor de sigma^2 = 8.978√ó10 ‚àí6 representa la varianza del error, con una alta verosimilitud (log likelihood) de 126732.8. Los criterios de informaci√≥n, AIC y BIC, son de -253463.6 y -253455.4, respectivamente, indicando un buen ajuste para este modelo sencillo. Las medidas de error en el conjunto de entrenamiento muestran un error medio () cercano cero (1.30e-06) y un RMSE de 0.002996, lo cual refleja una precisi√≥n razonable. La autocorrelaci√≥n en el primer rezago (ACF1) es baja (0.0035), sugiriendo independencia en los residuos.","code":"\n# Ajuste del modelo ARIMA\nforex_arima <- auto.arima(forex_diff)\nsummary(forex_arima)## Series: forex_diff \n## ARIMA(0,0,0) with zero mean \n## \n## sigma^2 = 8.978e-06:  log likelihood = 126732.8\n## AIC=-253463.6   AICc=-253463.6   BIC=-253455.4\n## \n## Training set error measures:\n##                        ME        RMSE         MAE MPE MAPE     MASE        ACF1\n## Training set 1.304966e-06 0.002996269 0.001979825 100  100 0.675058 0.003518741"},{"path":"preprocesamiento-y-visualizaci√≥n.html","id":"detecci√≥n-de-puntos-de-cambio","chapter":"3 Preprocesamiento y Visualizaci√≥n","heading":"3.8 Detecci√≥n de Puntos de Cambio","text":"Usaremos la funci√≥n cpt.mean para detectar cambios significativos en la media de la serie.se detectaron puntos de cambio, debido que despu√©s de la diferenciaci√≥n, se convierte b√°sicamente en ruido blanco.","code":""},{"path":"preprocesamiento-y-visualizaci√≥n.html","id":"media-cero-de-los-residuos","chapter":"3 Preprocesamiento y Visualizaci√≥n","heading":"3.9 Media Cero de los Residuos","text":"Comprobamos si la media de los residuos es cero.La prueba t de una muestra realizada sobre los residuos (residuals_arima) arroja un valor de ùë°=0.073986 con 28,858 grados de libertad y un valor p de 0.941. Dado que el valor p es significativamente mayor 0.05, rechazamos la hip√≥tesis nula de que la media de los residuos es igual cero. Esto sugiere que los residuos presentan un sesgo significativo. El intervalo de confianza del 95% para la media de los residuos y la media estimada muy cercana cero es consistente con un modelo bien ajustado sin tendencia sistem√°tica en los errores.","code":"\n# Prueba t en los residuos\nresiduals_arima <- residuals(forex_arima)\nt_test_residuals <- t.test(residuals_arima)\nprint(t_test_residuals)## \n##  One Sample t-test\n## \n## data:  residuals_arima\n## t = 0.073986, df = 28858, p-value = 0.941\n## alternative hypothesis: true mean is not equal to 0\n## 95 percent confidence interval:\n##  -3.326619e-05  3.587612e-05\n## sample estimates:\n##    mean of x \n## 1.304966e-06"},{"path":"preprocesamiento-y-visualizaci√≥n.html","id":"independencia-de-los-residuos","chapter":"3 Preprocesamiento y Visualizaci√≥n","heading":"3.10 Independencia de los Residuos","text":"Evaluamos la independencia de los residuos usando la prueba de Ljung-Box.Los datos cargados contienen 28,860 filas y 6 columnas de informaci√≥n sobre el tipo de cambio EUR/USD. La prueba de Dickey-Fuller Aumentada (ADF) realizada en tres configuraciones (sin constante ni tendencia, con constante sin tendencia, y con constante y tendencia) muestra valores ADF altamente negativos y p-valores menores o iguales 0.01, lo que indica que la serie diferenciada es estacionaria. Adem√°s, la prueba de Box-Ljung aplicada los residuos del modelo ARIMA arroja un valor de 30.772 con un valor p de 0.05827, lo cual sugiere que los residuos tienen autocorrelaci√≥n significativa, indicando independencia en los errores del modelo.","code":"\n# Prueba de independencia\nBox.test(residuals_arima, lag = 20, type = \"Ljung-Box\")## \n##  Box-Ljung test\n## \n## data:  residuals_arima\n## X-squared = 30.772, df = 20, p-value = 0.05827"},{"path":"preprocesamiento-y-visualizaci√≥n.html","id":"distribuci√≥n-de-los-residuos","chapter":"3 Preprocesamiento y Visualizaci√≥n","heading":"3.11 Distribuci√≥n de los Residuos","text":"Analizaremos la normalidad de los residuos con un gr√°fico Q-Q.El gr√°fico Q-Q muestra que los residuos del modelo se alinean con la normalidad en el centro de la distribuci√≥n, pero presentan desviaciones significativas en las colas. Esto sugiere que, aunque los residuos se comportan aproximadamente como una distribuci√≥n normal en el centro, tienen colas m√°s pesadas de lo esperado, lo que indica la presencia de valores extremos.","code":""},{"path":"an√°lisis-de-series-de-tiempo-con-el-m√©todo-holt-winters.html","id":"an√°lisis-de-series-de-tiempo-con-el-m√©todo-holt-winters","chapter":"4 An√°lisis de Series de Tiempo con el M√©todo Holt-Winters","heading":"4 An√°lisis de Series de Tiempo con el M√©todo Holt-Winters","text":"Este documento realiza un an√°lisis de series de tiempo utilizando el m√©todo de Holt-Winters aplicado exclusivamente la columna close del dataset EURUSD_ForexTrading_4hrs.csv. Se utilizar√°n solo 6000 datos, normalizando la columna close, dividiendo en conjunto de entrenamiento y prueba, y calculando la m√©tricas de error MAE en el conjunto de entrenamiento y en el conjunto de prueba.","code":""},{"path":"an√°lisis-de-series-de-tiempo-con-el-m√©todo-holt-winters.html","id":"carga-de-bibliotecas-y-datos","chapter":"4 An√°lisis de Series de Tiempo con el M√©todo Holt-Winters","heading":"4.1 Carga de Bibliotecas y Datos","text":"\nTable 4.1: Table 4.2: Primeras filas del dataset EURUSD ForexTrading 4hrs Columna close\nEl dataset EURUSD_ForexTrading_4hrs.csv contiene datos de trading del par de divisas EUR/USD con una frecuencia de 4 horas. Solo se ha seleccionado la columna close con los primeros 6000 datos para este an√°lisis.","code":""},{"path":"an√°lisis-de-series-de-tiempo-con-el-m√©todo-holt-winters.html","id":"normalizaci√≥n-de-la-columna-close","chapter":"4 An√°lisis de Series de Tiempo con el M√©todo Holt-Winters","heading":"4.2 Normalizaci√≥n de la Columna ‚Äòclose‚Äô","text":"\nTable 4.3: Table 4.4: Columna ‚Äòclose‚Äô Normalizada\nSe ha normalizado la columna close utilizando la t√©cnica Min-Max, transformando los valores entre 0 y 1 para mejorar la estabilidad del modelo.","code":""},{"path":"an√°lisis-de-series-de-tiempo-con-el-m√©todo-holt-winters.html","id":"descomposici√≥n-estacional","chapter":"4 An√°lisis de Series de Tiempo con el M√©todo Holt-Winters","heading":"4.3 Descomposici√≥n Estacional","text":"Descomponemos la serie temporal en componentes de tendencia, estacionalidad y ruido para analizar los patrones internos de la serie temporal antes de aplicar el modelo.","code":""},{"path":"an√°lisis-de-series-de-tiempo-con-el-m√©todo-holt-winters.html","id":"suavizado-exponencial-simple","chapter":"4 An√°lisis de Series de Tiempo con el M√©todo Holt-Winters","heading":"4.4 Suavizado Exponencial Simple","text":"Aplicamos el suavizado exponencial simple la serie close para visualizar una versi√≥n suavizada de la serie de tiempo. Se pude observar como la se√±al original contiene mas ruido que la suavizada.","code":""},{"path":"an√°lisis-de-series-de-tiempo-con-el-m√©todo-holt-winters.html","id":"suavizado-exponencial-doble-aditivo-y-multiplicativo","chapter":"4 An√°lisis de Series de Tiempo con el M√©todo Holt-Winters","heading":"4.5 Suavizado Exponencial Doble (Aditivo y Multiplicativo)","text":"Se puede apreciar que tanto el suavizado aditivo como el multiplicativo producen una estimaci√≥n cercana los datos originales, aunque estas se√±ales contienen mas ruido que el suavizado simple e incluso al parecer mas que la se√±al original.","code":""},{"path":"an√°lisis-de-series-de-tiempo-con-el-m√©todo-holt-winters.html","id":"calculo-de-error","chapter":"4 An√°lisis de Series de Tiempo con el M√©todo Holt-Winters","heading":"4.6 Calculo de error","text":"Se calcularon los errores de los modelos multiplicativo y aditivo en el dataset de training. Se usa un ajuste de 0.001 para el modelo multiplicativo, porque este requiere que todos los datos sean positivos y mayores que cero (admite ceros), y como los datos fueron nomalizados con min-max, obligatoriamente existe al menos un valor de cero.Finalmente se calcularon los errores de los modelos en el dataset de validaci√≥nEste gigantesco error es debido que el modelo trata de predecir todo el dataset de validaci√≥n de una sola vez (1238 ticks). En otros modelos predictivos en series de tiempo como redes neuronales, se usa un sliding window usando los √∫ltimos 128 ticks como entrada del modelo, se predice el siguiente, y esto se repite para cada tick, luego se promedian todos los errores y esa es la medida de desempe√±o de la red neuronal.Para poder comparar el desempe√±o predictivo del modelo Holt-Winter con otros modelos predictivos en una serie de tiempo larga como la nuestra, probablemente se requiera usar sliding window como en las redes neuronales, se requerir√≠a adaptar el modelo Holt-Winter para que se entrene con una ventana y prediga segmentos cortos que se concatenan y que formar√≠an la se√±al pronosticada, con la cual se calcular√≠an y promediar√≠an los errores por tick, en lugar de tratar de predecir la serie de tiempo completa de una sola vez.","code":"## MAE en entrenamiento (Aditivo): 0.01972768## MAE en entrenamiento (Multiplicativo): 0.05277391## MAE en validaci√≥n (Aditivo): 2.350168## MAE en validaci√≥n (Multiplicativo): 4.704901"},{"path":"an√°lisis-de-series-de-tiempo-con-el-m√©todo-holt-winters.html","id":"conclusiones","chapter":"4 An√°lisis de Series de Tiempo con el M√©todo Holt-Winters","heading":"4.7 Conclusiones","text":"El m√©todo Holt-Winters aplicado la columna close del conjunto de datos muestra que este modelo es capaz de capturar patrones de tendencia y estacionalidad en los datos de precios de cierre normalizados. Las m√©tricas de evaluaci√≥n como MAE muestran la precisi√≥n del modelo tanto en el conjunto de entrenamiento como en el conjunto de prueba, donde se puede apreciar que la predicci√≥n de todo el dataset de validaci√≥n completo es una buena forma de evaluar el desempe√±o de estos modelos, especialmente para comaprarlos con modelos ampliamente usados como las redes neuronales.","code":""},{"path":"modelos-estacionarios.html","id":"modelos-estacionarios","chapter":"5 Modelos Estacionarios","heading":"5 Modelos Estacionarios","text":"En esta secci√≥n, analizamos y predecimos series temporales usando la metodolog√≠a Box-Jenkins. El objetivo es ajustar modelos autoregresivos integrados de media m√≥vil (ARIMA) para encontrar patrones subyacentes en los datos y realizar predicciones futuras.El dataset analizado contiene precios Forex EUR/USD en intervalos de 4 horas, el cual ser√° procesado y transformado para cumplir con los requisitos de estacionariedad y ajuste de modelos ARIMA.","code":""},{"path":"modelos-estacionarios.html","id":"objetivo","chapter":"5 Modelos Estacionarios","heading":"5.1 Objetivo","text":"Esquematizar los modelos convencionales de series temporales mediante la metodolog√≠a Box-Jenkins y explorar su aplicabilidad en la predicci√≥n de futuras observaciones.","code":""},{"path":"modelos-estacionarios.html","id":"carga-y-exploraci√≥n-de-los-datos","chapter":"5 Modelos Estacionarios","heading":"5.2 1. Carga y Exploraci√≥n de los Datos","text":"En esta secci√≥n se carga el dataset EURUSD_ForexTrading_4hrs.csv, y se realiza una exploraci√≥n inicial para entender su estructura y caracter√≠sticas b√°sicas.","code":"##                  Gmt.time    open    high     low   close   volume\n## 1 04.05.2003 21:00:00.000 1.12354 1.12354 1.12166 1.12274  95533.1\n## 2 05.05.2003 01:00:00.000 1.12242 1.12276 1.12067 1.12126  93778.6\n## 3 05.05.2003 05:00:00.000 1.12139 1.12255 1.12030 1.12113  90924.7\n## 4 05.05.2003 09:00:00.000 1.12092 1.12331 1.12049 1.12174  91254.7\n## 5 05.05.2003 13:00:00.000 1.12194 1.12900 1.12130 1.12712 308003.4\n## 6 05.05.2003 17:00:00.000 1.12718 1.13019 1.12657 1.12804 373668.3##    Gmt.time              open            high            low       \n##  Length:28860       Min.   :1.037   Min.   :1.039   Min.   :1.034  \n##  Class :character   1st Qu.:1.154   1st Qu.:1.156   1st Qu.:1.152  \n##  Mode  :character   Median :1.242   Median :1.244   Median :1.240  \n##                     Mean   :1.254   Mean   :1.256   Mean   :1.252  \n##                     3rd Qu.:1.339   3rd Qu.:1.341   3rd Qu.:1.337  \n##                     Max.   :1.599   Max.   :1.604   Max.   :1.597  \n##      close           volume      \n##  Min.   :1.037   Min.   :     0  \n##  1st Qu.:1.154   1st Qu.: 20322  \n##  Median :1.242   Median : 47813  \n##  Mean   :1.254   Mean   : 83079  \n##  3rd Qu.:1.339   3rd Qu.:102455  \n##  Max.   :1.599   Max.   :752269"},{"path":"modelos-estacionarios.html","id":"limpieza-y-preprocesamiento-de-los-datos","chapter":"5 Modelos Estacionarios","heading":"5.3 2. Limpieza y Preprocesamiento de los Datos","text":"Se seleccionan las columnas relevantes (en este caso, Close) y se convierten en una serie temporal.El gr√°fico representa la serie temporal original del precio de cierre del par Forex EUR/USD, registrado en intervalos de 4 horas. Observamos fluctuaciones significativas que reflejan los cambios en el mercado durante el per√≠odo analizado. La serie muestra patrones evidentes de tendencias ascendentes y descendentes, lo que sugiere posibles componentes de largo plazo y estacionalidad que deben ser tratados en etapas posteriores del an√°lisis, como la transformaci√≥n estacionariedad y la descomposici√≥n de los datos.","code":""},{"path":"modelos-estacionarios.html","id":"divisi√≥n-del-dataset-en-conjuntos-de-entrenamiento-y-validaci√≥n","chapter":"5 Modelos Estacionarios","heading":"5.4 3. Divisi√≥n del Dataset en Conjuntos de Entrenamiento y Validaci√≥n","text":"Se divide el dataset en 70% para entrenamiento y 30% para evaluaci√≥n del modelo.","code":""},{"path":"modelos-estacionarios.html","id":"normalizaci√≥n-de-los-datos","chapter":"5 Modelos Estacionarios","heading":"5.5 4. Normalizaci√≥n de los Datos","text":"La normalizaci√≥n es √∫til para estabilizar la varianza y hacer que los datos sean m√°s adecuados para el an√°lisis.Como se observa, el rango de los datos ahora se encuentra entre 0 y 1.","code":""},{"path":"modelos-estacionarios.html","id":"verificaci√≥n-de-estacionariedad","chapter":"5 Modelos Estacionarios","heading":"5.6 5. Verificaci√≥n de Estacionariedad","text":"La serie debe ser estacionaria para que los modelos ARIMA sean v√°lidos. Evaluamos esto usando la prueba Dickey-Fuller Aumentada (ADF).El resultado de la prueba Dickey-Fuller Aumentada (ADF) muestra un estad√≠stico Dickey-Fuller de -2.0393 con un p-valor de 0.5618, lo que indica que podemos rechazar la hip√≥tesis nula de que la serie tiene una ra√≠z unitaria. Esto significa que la serie norm_train_data es estacionaria. Dado que la estacionariedad es un requisito fundamental para ajustar modelos ARIMA, ser√° necesario transformar la serie, aplicando una diferenciaci√≥n para estabilizar su media y eliminar tendencias.","code":"## Augmented Dickey-Fuller Test \n## alternative: stationary \n##  \n## Type 1: no drift no trend \n##       lag    ADF p.value\n##  [1,]   0 -0.861   0.372\n##  [2,]   1 -0.868   0.369\n##  [3,]   2 -0.874   0.367\n##  [4,]   3 -0.861   0.372\n##  [5,]   4 -0.874   0.367\n##  [6,]   5 -0.876   0.366\n##  [7,]   6 -0.878   0.365\n##  [8,]   7 -0.874   0.367\n##  [9,]   8 -0.875   0.367\n## [10,]   9 -0.873   0.367\n## [11,]  10 -0.877   0.366\n## [12,]  11 -0.886   0.363\n## [13,]  12 -0.885   0.363\n## [14,]  13 -0.876   0.366\n## Type 2: with drift no trend \n##       lag   ADF p.value\n##  [1,]   0 -2.12   0.278\n##  [2,]   1 -2.15   0.268\n##  [3,]   2 -2.17   0.261\n##  [4,]   3 -2.13   0.276\n##  [5,]   4 -2.14   0.273\n##  [6,]   5 -2.14   0.272\n##  [7,]   6 -2.14   0.272\n##  [8,]   7 -2.13   0.275\n##  [9,]   8 -2.11   0.285\n## [10,]   9 -2.10   0.287\n## [11,]  10 -2.11   0.285\n## [12,]  11 -2.09   0.292\n## [13,]  12 -2.09   0.291\n## [14,]  13 -2.08   0.298\n## Type 3: with drift and trend \n##       lag   ADF p.value\n##  [1,]   0 -2.16   0.507\n##  [2,]   1 -2.19   0.496\n##  [3,]   2 -2.21   0.489\n##  [4,]   3 -2.17   0.505\n##  [5,]   4 -2.18   0.501\n##  [6,]   5 -2.18   0.501\n##  [7,]   6 -2.18   0.501\n##  [8,]   7 -2.17   0.504\n##  [9,]   8 -2.15   0.514\n## [10,]   9 -2.14   0.517\n## [11,]  10 -2.15   0.514\n## [12,]  11 -2.13   0.523\n## [13,]  12 -2.13   0.521\n## [14,]  13 -2.11   0.528\n## ---- \n## Note: in fact, p.value = 0.01 means p.value <= 0.01## $type1\n##       lag        ADF   p.value\n##  [1,]   0 -0.8607895 0.3716268\n##  [2,]   1 -0.8679287 0.3690726\n##  [3,]   2 -0.8742777 0.3668010\n##  [4,]   3 -0.8606220 0.3716867\n##  [5,]   4 -0.8741001 0.3668646\n##  [6,]   5 -0.8764373 0.3660284\n##  [7,]   6 -0.8781312 0.3654224\n##  [8,]   7 -0.8743629 0.3667706\n##  [9,]   8 -0.8746145 0.3666806\n## [10,]   9 -0.8733773 0.3671232\n## [11,]  10 -0.8765659 0.3659824\n## [12,]  11 -0.8856760 0.3627230\n## [13,]  12 -0.8848509 0.3630182\n## [14,]  13 -0.8762256 0.3661041\n## \n## $type2\n##       lag       ADF   p.value\n##  [1,]   0 -2.124490 0.2782040\n##  [2,]   1 -2.149853 0.2680589\n##  [3,]   2 -2.166670 0.2613321\n##  [4,]   3 -2.129695 0.2761221\n##  [5,]   4 -2.138047 0.2727812\n##  [6,]   5 -2.140018 0.2719927\n##  [7,]   6 -2.139519 0.2721925\n##  [8,]   7 -2.132869 0.2748525\n##  [9,]   8 -2.108596 0.2845615\n## [10,]   9 -2.102436 0.2870256\n## [11,]  10 -2.108329 0.2846684\n## [12,]  11 -2.089681 0.2921277\n## [13,]  12 -2.093017 0.2907933\n## [14,]  13 -2.075880 0.2976481\n## \n## $type3\n##       lag       ADF   p.value\n##  [1,]   0 -2.164022 0.5068136\n##  [2,]   1 -2.189210 0.4961222\n##  [3,]   2 -2.205776 0.4891471\n##  [4,]   3 -2.169354 0.5045398\n##  [5,]   4 -2.176674 0.5014184\n##  [6,]   5 -2.178475 0.5006505\n##  [7,]   6 -2.177817 0.5009308\n##  [8,]   7 -2.171376 0.5036774\n##  [9,]   8 -2.146670 0.5142130\n## [10,]   9 -2.140507 0.5168410\n## [11,]  10 -2.146217 0.5144060\n## [12,]  11 -2.126486 0.5228201\n## [13,]  12 -2.129930 0.5213512\n## [14,]  13 -2.113231 0.5284725"},{"path":"modelos-estacionarios.html","id":"transformaci√≥n-a-estacionariedad","chapter":"5 Modelos Estacionarios","heading":"5.7 6. Transformaci√≥n a Estacionariedad","text":"Si la serie es estacionaria, aplicamos una diferenciaci√≥n para eliminar tendencias deseadas.El gr√°fico muestra la serie diferenciada con valores oscilando alrededor de 0, entre aproximadamente -0.02 y 0.02. Esto indica que la diferenciaci√≥n logr√≥ estabilizar la media y eliminar tendencias, dejando la serie preparada para verificar su estacionariedad y ajustar un modelo ARIMA.","code":""},{"path":"modelos-estacionarios.html","id":"an√°lisis-acf-y-pacf","chapter":"5 Modelos Estacionarios","heading":"5.8 7. An√°lisis ACF y PACF","text":"Los gr√°ficos de ACF y PACF ayudan determinar los valores \\(p\\) y \\(q\\) del modelo ARIMA.El gr√°fico de la ACF (Funci√≥n de Autocorrelaci√≥n) muestra un primer retardo significativo, con un valor cercano 1.0, mientras que los retardos restantes est√°n dentro de los intervalos de confianza (¬±0.05), indicando que hay correlaci√≥n significativa m√°s all√° del primer lag.En el gr√°fico de la PACF (Funci√≥n de Autocorrelaci√≥n Parcial), los primeros retardos presentan valores significativos positivos y negativos, especialmente en los primeros lags, como el 1, 3 y 5. Esto sugiere la posible inclusi√≥n de t√©rminos autorregresivos (AR) en el modelo ARIMA.Estos resultados gu√≠an la selecci√≥n de los par√°metros para ajustar un modelo ARIMA adecuado.","code":""},{"path":"modelos-estacionarios.html","id":"ajuste-del-modelo-arima","chapter":"5 Modelos Estacionarios","heading":"5.9 8. Ajuste del Modelo ARIMA","text":"Ajustamos un modelo ARIMA utilizando los valores \\(p\\), \\(d\\) y \\(q\\) obtenidos previamente. Usamos auto.arima para seleccionar autom√°ticamente los mejores par√°metros.El modelo ajustado sobre la serie normalizada (norm_train_data) es un ARIMA(4,1,0) con los siguientes coeficientes: - AR1: 0.0095 (s.e.: 0.0070), - AR2: 0.0075 (s.e.: 0.0070), - AR3: -0.0163 (s.e.: 0.0070), - AR4: 0.0121 (s.e.: 0.0070).Indicadores del modelo: - Log-Likelihood: 74553.92, - AIC: -149097.8, - BIC: -149058.3.M√©tricas del conjunto de entrenamiento: - RMSE: 0.0060, - MAE: 0.0041, - ACF1: -0.000026.Estos resultados indican un ajuste razonable del modelo los datos normalizados, con residuos independientes y m√©tricas de error bajas en el conjunto de entrenamiento. Sin embargo, la presencia de valores extremos en las m√©tricas como MAPE y MPE (\\(-\\infty, \\infty\\)) sugiere posibles problemas en los c√°lculos debido la normalizaci√≥n o valores cercanos cero.","code":"## Series: norm_train_data \n## ARIMA(4,1,0) \n## \n## Coefficients:\n##          ar1     ar2      ar3     ar4\n##       0.0095  0.0075  -0.0163  0.0121\n## s.e.  0.0070  0.0070   0.0070  0.0070\n## \n## sigma^2 = 3.647e-05:  log likelihood = 74553.92\n## AIC=-149097.8   AICc=-149097.8   BIC=-149058.3\n## \n## Training set error measures:\n##                         ME        RMSE         MAE  MPE MAPE     MASE\n## Training set -2.667179e-07 0.006038687 0.004067731 -Inf  Inf 1.000317\n##                       ACF1\n## Training set -2.599614e-05"},{"path":"modelos-estacionarios.html","id":"validaci√≥n-del-modelo","chapter":"5 Modelos Estacionarios","heading":"5.10 9. Validaci√≥n del Modelo","text":"Se validan los supuestos del modelo mediante el an√°lisis de los residuos.El an√°lisis de los residuos del modelo ARIMA(4,1,0) muestra lo siguiente:Gr√°fico de Residuos: Los residuos oscilan alrededor de 0, con valores en el rango de aproximadamente -0.02 0.02, sin patrones visibles ni tendencias evidentes, lo que sugiere independencia de los residuos.Gr√°fico de Residuos: Los residuos oscilan alrededor de 0, con valores en el rango de aproximadamente -0.02 0.02, sin patrones visibles ni tendencias evidentes, lo que sugiere independencia de los residuos.ACF de Residuos: Los valores de autocorrelaci√≥n de los residuos est√°n mayoritariamente dentro de los intervalos de confianza (¬±0.02), excepto por algunos picos en retardos altos, indicando que los residuos son casi ruido blanco.ACF de Residuos: Los valores de autocorrelaci√≥n de los residuos est√°n mayoritariamente dentro de los intervalos de confianza (¬±0.02), excepto por algunos picos en retardos altos, indicando que los residuos son casi ruido blanco.Distribuci√≥n de Residuos: El histograma muestra una distribuci√≥n aproximadamente normal centrada en 0, corroborada por la curva de densidad ajustada, lo que valida la suposici√≥n de normalidad en los residuos.Distribuci√≥n de Residuos: El histograma muestra una distribuci√≥n aproximadamente normal centrada en 0, corroborada por la curva de densidad ajustada, lo que valida la suposici√≥n de normalidad en los residuos.Estos resultados indican que el modelo ajustado cumple los supuestos de independencia y normalidad de los residuos, validando su uso para predicci√≥n.El resultado de la prueba Box-Ljung para los residuos del modelo muestra un estad√≠stico \\(X^2 = 0.91976\\) con \\(df = 10\\) grados de libertad y un \\(p\\text{-valor} = 0.9999\\). Dado que el \\(p\\text{-valor} \\gg 0.05\\), se puede rechazar la hip√≥tesis nula de que los residuos son ruido blanco, confirmando la independencia de los residuos y validando el ajuste del modelo.Dado que el \\(p\\text{-valor} > 0.05\\), se puede rechazar la hip√≥tesis nula de que los residuos son ruido blanco. Esto confirma que los residuos del modelo presentan autocorrelaci√≥n significativa, validando as√≠ el ajuste del modelo ARIMA.","code":"## \n##  Ljung-Box test\n## \n## data:  Residuals from ARIMA(4,1,0)\n## Q* = 0.91976, df = 6, p-value = 0.9885\n## \n## Model df: 4.   Total lags used: 10## \n##  Box-Ljung test\n## \n## data:  model$residuals\n## X-squared = 0.91976, df = 10, p-value = 0.9999"},{"path":"modelos-estacionarios.html","id":"predicci√≥n","chapter":"5 Modelos Estacionarios","heading":"5.11 10. Predicci√≥n","text":"Realizamos predicciones para los pr√≥ximos intervalos usando el modelo ajustado.El gr√°fico muestra la serie temporal original superpuesta con la predicci√≥n generada por el modelo ARIMA(4,1,0). Aunque las predicciones siguen la tendencia general de la serie, el resultado es muy similar al original debido que el modelo representa una diferenciaci√≥n de primer orden, capturando √∫nicamente cambios incrementales sin agregar t√©rminos de media m√≥vil (\\(q\\)) y usando 4 para el autorregresivo.","code":""},{"path":"modelos-estacionarios.html","id":"evaluaci√≥n-de-predicciones","chapter":"5 Modelos Estacionarios","heading":"5.12 11. Evaluaci√≥n de Predicciones","text":"Se eval√∫an las predicciones contra los datos de prueba usando m√©tricas de error.El error absoluto medio (MAE) del modelo en el conjunto de entrenamiento es 0.00406, mientras que en el conjunto de prueba es significativamente mayor, con un valor de 0.0772. Esto sugiere que el modelo se ajusta bien los datos de entrenamiento, pero tiene dificultades para generalizar datos vistos, indicando un posible sobreajuste o la necesidad de mejorar la capacidad predictiva del modelo.","code":"## MAE en el conjunto de entrenamiento: 0.004067731## MAE en el conjunto de prueba: 0.07728354"},{"path":"modelos-estacionarios.html","id":"conclusiones-1","chapter":"5 Modelos Estacionarios","heading":"5.13 12. Conclusiones","text":"Las siguientes son las conlusiones de las actividares realizadas:Ajuste del Modelo ARIMA:\nUn modelo ARIMA(4,1,0), incorpor√≥ t√©rminos autorregresivos (\\(p = 4\\)) y mostr√≥ mejoras sutiles respecto al ARIMA(0,1,0) probado inicialmente en los indicadores como log-likelihood = 74553.92 y AIC = -149097.8, con residuos que cumplen las suposiciones de ruido blanco y normalidad.\nUn modelo ARIMA(4,1,0), incorpor√≥ t√©rminos autorregresivos (\\(p = 4\\)) y mostr√≥ mejoras sutiles respecto al ARIMA(0,1,0) probado inicialmente en los indicadores como log-likelihood = 74553.92 y AIC = -149097.8, con residuos que cumplen las suposiciones de ruido blanco y normalidad.Validaci√≥n del Modelo:\nLa prueba Box-Ljung confirm√≥ que los residuos del modelo ARIMA(4,1,0) son independientes y presentan autocorrelaci√≥n significativa (\\(p\\text{-valor} = 0.9999\\)).\nLos residuos mostraron una distribuci√≥n aproximadamente normal, validando a√∫n m√°s la calidad del modelo ajustado.\nLa prueba Box-Ljung confirm√≥ que los residuos del modelo ARIMA(4,1,0) son independientes y presentan autocorrelaci√≥n significativa (\\(p\\text{-valor} = 0.9999\\)).Los residuos mostraron una distribuci√≥n aproximadamente normal, validando a√∫n m√°s la calidad del modelo ajustado.Evaluaci√≥n de Predicciones:\nEl MAE en el conjunto de entrenamiento fue de 0.00406, mientras que en el conjunto de prueba aument√≥ significativamente 0.07728354, lo que indica que el modelo tiene dificultades para generalizar datos vistos, posiblemente debido sobreajuste o caracter√≠sticas complejas capturadas.\nEl MAE en el conjunto de entrenamiento fue de 0.00406, mientras que en el conjunto de prueba aument√≥ significativamente 0.07728354, lo que indica que el modelo tiene dificultades para generalizar datos vistos, posiblemente debido sobreajuste o caracter√≠sticas complejas capturadas.Limitaciones y Mejoras:\nAunque el modelo ARIMA(4,1,0) ofrece un mejor ajuste que el ARIMA(0,1,0), logra reducir el error en el conjunto de prueba de forma significativa.\nSer√≠a recomendable explorar modelos m√°s avanzados, como SARIMA, para capturar componentes estacionales, o incluir variables ex√≥genas para mejorar las predicciones.\nAunque el modelo ARIMA(4,1,0) ofrece un mejor ajuste que el ARIMA(0,1,0), logra reducir el error en el conjunto de prueba de forma significativa.Ser√≠a recomendable explorar modelos m√°s avanzados, como SARIMA, para capturar componentes estacionales, o incluir variables ex√≥genas para mejorar las predicciones.El uso de la metodolog√≠a Box-Jenkins permiti√≥ identificar patrones y ajustar modelos que explican las caracter√≠sticas principales de la serie temporal. Sin embargo, la discrepancia entre el desempe√±o en los conjuntos de entrenamiento y prueba resalta la necesidad de modelos m√°s robustos para mejorar la capacidad predictiva.","code":""}]
