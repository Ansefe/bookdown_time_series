% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
]{book}
\usepackage{amsmath,amssymb}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math} % this also loads fontspec
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else
  % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}
\usepackage{booktabs}
\usepackage{amsthm}
\makeatletter
\def\thm@space@setup{%
  \thm@preskip=8pt plus 2pt minus 4pt
  \thm@postskip=\thm@preskip
}
\makeatother
\usepackage{booktabs}
\usepackage{longtable}
\usepackage{array}
\usepackage{multirow}
\usepackage{wrapfig}
\usepackage{float}
\usepackage{colortbl}
\usepackage{pdflscape}
\usepackage{tabu}
\usepackage{threeparttable}
\usepackage{threeparttablex}
\usepackage[normalem]{ulem}
\usepackage{makecell}
\usepackage{xcolor}
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\usepackage[]{natbib}
\bibliographystyle{apalike}
\usepackage{bookmark}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same}
\hypersetup{
  pdftitle={EUR/USD},
  pdfauthor={Harvey Bastidas, Andr√©s Caicedo, Alexander Alvarado},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}

\title{EUR/USD}
\author{Harvey Bastidas, Andr√©s Caicedo, Alexander Alvarado}
\date{2024-11-19}

\begin{document}
\maketitle

{
\setcounter{tocdepth}{1}
\tableofcontents
}
\chapter{Justificaci√≥n de elecci√≥n del Dataset}\label{justificaciuxf3n-de-elecciuxf3n-del-dataset}

\textbf{Integrantes}:\\
Harvey Bastidas, Alexander Alvarado y Andr√©s Caicedo\\
\textbf{Materia}:\\
An√°lisis de series de tiempo\\
\textbf{Profesora}:\\
Isabel Cristina Garc√≠a

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Informaci√≥n del Dataset}\label{informaciuxf3n-del-dataset}

El dataset seleccionado para este an√°lisis es el siguiente: \href{https://www.kaggle.com/datasets/chandrimad31/eurusd-forex-trading-data-20032021}{EUR/USD Forex Trading Data (2003-2021)}, el cual fue extra√≠do de \href{https://forex.tradingcharts.com/}{Forex Trading Charts}, propiedad de Barchart Solutions, una empresa especializada en servicios financieros en los Estados Unidos. Barchart Solutions cuenta con reconocidos clientes como el Banco Goldman Sachs y el Bank of Canada, lo que nos lleva a concluir que los datos ofrecidos son confiables y precisos para realizar an√°lisis financieros.

La empresa matriz, \textbf{Barchart Solutions}, tiene su sede en:

\textbf{222 S. Riverside Plaza, Suite 810,\\
Chicago, IL 60606, Estados Unidos}

El dataset presenta las tasas de cambio del par de divisas EUR/USD desde el \textbf{5 de mayo de 2003} hasta el \textbf{16 de octubre de 2021}, con una periodicidad de \textbf{4 horas}. Este conjunto de datos incluye las siguientes 6 columnas:

\begin{itemize}
\tightlist
\item
  \textbf{Open}: Precio de apertura para el periodo.
\item
  \textbf{High}: Precio m√°ximo durante el periodo.
\item
  \textbf{Low}: Precio m√≠nimo durante el periodo.
\item
  \textbf{Close}: Precio de cierre para el periodo.
\item
  \textbf{Volume}: Volumen de transacciones reportado.
\end{itemize}

Es importante resaltar que los datos no contienen valores nulos ni perdidos para los d√≠as de semana, aunque no se registran valores durante los fines de semana, lo que es normal en los mercados de Forex.

El an√°lisis se centrar√° en la columna \textbf{Close}, que representa el precio de cierre, dado que es la variable m√°s relevante para el pron√≥stico de tendencias.

\section{Justificaci√≥n de la Elecci√≥n del Dataset}\label{justificaciuxf3n-de-la-elecciuxf3n-del-dataset}

La elecci√≥n de este dataset se fundamenta en la importancia de analizar la tasa de cambio EUR/USD, uno de los pares de divisas m√°s negociados en el mercado Forex. La predicci√≥n de la tendencia de la tasa de cambio es crucial para varias estrategias financieras, como el balanceo de portafolios de inversi√≥n. En este contexto, se pueden usar tanto la \textbf{Teor√≠a Moderna de Portafolios (MPT)} como la \textbf{Teor√≠a de Portafolios Post-Moderna (PMPT)}, que son ampliamente utilizadas en la optimizaci√≥n de la distribuci√≥n de activos. Ambas teor√≠as se benefician de predicciones precisas de la tendencia de los activos subyacentes, como es el caso de las divisas.

Adem√°s, este dataset ofrece una excelente relaci√≥n se√±al-ruido, lo que mejora la predictibilidad de los modelos basados en series de tiempo. Utilizamos el \textbf{coeficiente de variaci√≥n (CV)} como criterio para seleccionar este dataset, debido a que es una m√©trica robusta para medir la variabilidad en relaci√≥n con la media. Un CV bajo indica que la variabilidad en los datos es relativamente baja, lo que es favorable para la predicci√≥n de tendencias.

El \textbf{coeficiente de variaci√≥n} calculado para la columna ``Close'' de este dataset es de aproximadamente \textbf{9.5\%}, lo que lo convierte en el m√°s bajo entre los datasets que evaluamos. Esto lo hace ideal para el pron√≥stico, ya que un CV bajo sugiere que la se√±al en los datos es fuerte en comparaci√≥n con el ruido.

\subsection{Relaci√≥n con el Signal-to-Noise Ratio (SNR)}\label{relaciuxf3n-con-el-signal-to-noise-ratio-snr}

El \textbf{coeficiente de variaci√≥n (CV)} est√° inversamente relacionado con el \textbf{Signal-to-Noise Ratio (SNR)}, una m√©trica com√∫nmente utilizada en el procesamiento de se√±ales. El SNR mide la proporci√≥n de la potencia de la se√±al con respecto a la del ruido, lo que ayuda a evaluar la calidad de los datos.

El SNR para este dataset se calcula como el cuadrado del inverso del CV. Para el EUR/USD, con un CV de \textbf{0.09}, el SNR es aproximadamente:

\[
SNR = \left(\frac{1}{0.09}\right)^2 \approx 123
\]

Este valor indica que la se√±al es mucho m√°s fuerte que el ruido en este dataset. En contraste, otro dataset que probamos, con un CV de \textbf{20\%}, ten√≠a un SNR mucho menor, alrededor de \textbf{25}. La diferencia muestra que el dataset de EUR/USD tiene una mayor preponderancia de se√±al sobre el ruido, lo que permite una mejor predictibilidad en los modelos de pron√≥stico.

Dado que sabemos que el \textbf{SNR} es aprox \textbf{123}, esto significa que el ruido es aprox 1/123 = \textbf{0.008} que nos da una idea del m√°ximo error absoluto (\textbf{MAE}) en los datos Normalizados en el pron√≥sitco del siguiente periodo que podemos obtener, ya que errores por debajo de este valor probablemente incluir√≠an la predicci√≥n del ruido y podr√≠an ser indicador de overfitting en el modelo predictivo usado.

\section{Importancia de Analizar este Dataset}\label{importancia-de-analizar-este-dataset}

La capacidad de predecir con precisi√≥n la tasa de cambio EUR/USD tiene m√∫ltiples aplicaciones en el sector financiero. En primer lugar, es fundamental para el \textbf{trading de divisas (Forex)}, donde una mejor predicci√≥n de las tendencias puede resultar en decisiones de inversi√≥n m√°s acertadas. Adem√°s, es esencial para la gesti√≥n de portafolios financieros, ya que permite el uso de herramientas como la \textbf{Teor√≠a Moderna de Portafolios (MPT)}, donde la diversificaci√≥n se realiza teniendo en cuenta tanto la tendencia como la variabilidad de los activos.

Por lo tanto, este dataset fue seleccionado debido a su alta calidad y baja variabilidad, lo que lo hace ideal para el an√°lisis predictivo en el mercado de Forex, as√≠ como en la gesti√≥n de portafolios. El alto \textbf{SNR} nos da confianza en que las predicciones basadas en este dataset ser√°n precisas y √∫tiles en un entorno real, al mismo tiempo que nos alerta sobre los l√≠mites predictivos en funci√≥n del ruido presente en los datos.

\chapter{Estructura de los datos}\label{intro}

Con el prop√≥sito de observar las tendencias y cambios estructurales en la serie, se realizan pruebas estad√≠sticas para conocer la estructura subyacente de la serie.

\section{C√°lculo de Medias M√≥viles Simples:}\label{cuxe1lculo-de-medias-muxf3viles-simples}

El c√°lculo de medias m√≥viles es una t√©cnica com√∫n en el an√°lisis de series de tiempo utilizada para suavizar las fluctuaciones a corto plazo y destacar las tendencias subyacentes en los datos. En este an√°lisis, se implementan medias m√≥viles de corto y largo plazo para identificar patrones de comportamiento y ayudar en la toma de decisiones basadas en tendencias m√°s claras.

\includegraphics{bookdown_time_series_files/figure-latex/unnamed-chunk-3-1.pdf}

\begin{itemize}
\item
  \textbf{Media m√≥vil de 50 periodos (MA corta)}:

  \begin{itemize}
  \item
    Sigue de cerca las fluctuaciones del precio de cierre, respondiendo r√°pidamente a los cambios de tendencia.
  \item
    Captura las tendencias a \textbf{corto plazo}, pero tambi√©n refleja mucha volatilidad.
  \end{itemize}
\item
  \textbf{Media m√≥vil de 500 periodos (MA larga)}:

  \begin{itemize}
  \item
    Se mueve de forma m√°s suave, reaccionando m√°s lentamente a los cambios de precios.
  \item
    Indica la \textbf{tendencia a largo plazo}, proporcionando una visi√≥n m√°s estable del comportamiento del mercado.
  \end{itemize}
\end{itemize}

\section{An√°lisis de Rezagos}\label{anuxe1lisis-de-rezagos}

C√≥mo se comporta la serie de tiempo con respecto a sus valores pasados, introduciendo rezagos.

\includegraphics{bookdown_time_series_files/figure-latex/unnamed-chunk-5-1.pdf}

En cada uno de los gr√°ficos, los puntos siguen una l√≠nea casi perfectamente recta, sugiriendo una \textbf{alta autocorrelaci√≥n} entre los valores de la serie con sus rezagos cercanos.

La pendiente positiva indica que cuando el valor anterior era alto, el valor actual tambi√©n tiende a ser alto, y lo mismo sucede para valores bajos. Esto sugiere que \textbf{la serie es muy persistente}, es decir, los precios tienden a seguir una direcci√≥n similar en el corto plazo.

Dado que no hay patrones dispersos o sin forma definida, se puede inferir que la serie no tiene cambios abruptos o comportamiento ca√≥tico entre los puntos cercanos. Esto podr√≠a indicar que \textbf{no hay mucha volatilidad} en los intervalos de 4 horas.

\section{An√°lisis de Estacionalidad}\label{anuxe1lisis-de-estacionalidad}

Para detectar si existe estacionalidad (patrones repetitivos), utilizaremos \textbf{decomposici√≥n} o \textbf{test de estacionalidad}.

\includegraphics{bookdown_time_series_files/figure-latex/unnamed-chunk-6-1.pdf}

En la gr√°fica de \textbf{descomposici√≥n de series de tiempo} se visualizan los \textbf{componentes de la serie}: datos originales, estacionalidad, tendencia y residuales (remainder):

1. \textbf{Datos Originales (data):} En la primera gr√°fica (data), se observan los valores de cierre a lo largo del tiempo. Vemos fluctuaciones en los precios con algunas subidas y bajadas claras, lo que indica la volatilidad normal del mercado Forex.

2. \textbf{Componente Estacional (seasonal):} El segundo gr√°fico muestra un \textbf{patr√≥n repetitivo y peri√≥dico}. Este patr√≥n sugiere que hay \textbf{ciclos regulares} en la serie. La estacionalidad se mantiene constante a lo largo del tiempo, lo que indica que ciertos movimientos en el mercado se repiten con una periodicidad fija (en este caso, podr√≠a ser diaria o semanal). Es probable que este componente estacional refleje la actividad c√≠clica en horarios espec√≠ficos o d√≠as determinados, como mayor volatilidad durante sesiones overlap (como entre Londres y Nueva York).

3. \textbf{Componente de Tendencia (trend):} El tercer gr√°fico muestra una \textbf{tendencia suavizada} que sigue la direcci√≥n general del mercado. Observamos fases de \textbf{alzas y ca√≠das}: primero hay una subida clara, luego una ca√≠da, y finalmente otra leve tendencia hacia la estabilidad.

4. \textbf{Componente de Residuos o Resto (remainder):} El √∫ltimo gr√°fico (remainder) muestra los \textbf{residuos} o la parte de los datos que no es explicada por la tendencia ni la estacionalidad. Estos residuos parecen ser \textbf{ruido blanco}, con fluctuaciones alrededor de cero, lo que indica que no hay patrones significativos adicionales no capturados por los otros componentes.

\chapter{Preprocesamiento y Visualizaci√≥n}\label{preprocesamiento-y-visualizaciuxf3n}

En este an√°lisis, trabajaremos con el dataset de tipo de cambio EUR/USD de Forex proporcionado, el cual incluye datos hist√≥ricos de 2003 a 2021. El objetivo es estudiar las tendencias, estacionalidad y comportamiento estructural de la serie de tiempo. Adem√°s, evaluaremos si es necesario realizar transformaciones en la serie para estabilizar la varianza y facilitar la predicci√≥n.

\section{Descomposici√≥n de la Serie de Tiempo}\label{descomposiciuxf3n-de-la-serie-de-tiempo}

En esta etapa se busca realizar la descomposici√≥n de la serie de tiempo para identificar los componentes de \textbf{tendencia}, \textbf{estacionalidad} y \textbf{residuos}.

\includegraphics{bookdown_time_series_files/figure-latex/unnamed-chunk-8-1.pdf}

En la gr√°fica de \textbf{descomposici√≥n de series de tiempo} se visualizan los \textbf{componentes de la serie}: datos originales, estacionalidad, tendencia y residuales (remainder):

1. \textbf{Datos Originales (data):} En la primera gr√°fica (data), se observan los valores de cierre a lo largo del tiempo. Vemos fluctuaciones en los precios con algunas subidas y bajadas claras, lo que indica la volatilidad normal del mercado Forex.

2. \textbf{Componente Estacional (seasonal):} El segundo gr√°fico muestra un \textbf{patr√≥n repetitivo y peri√≥dico}. Este patr√≥n sugiere que hay \textbf{ciclos regulares} en la serie. La estacionalidad se mantiene constante a lo largo del tiempo, lo que indica que ciertos movimientos en el mercado se repiten con una periodicidad fija (en este caso, podr√≠a ser diaria o semanal). Es probable que este componente estacional refleje la actividad c√≠clica en horarios espec√≠ficos o d√≠as determinados, como mayor volatilidad durante sesiones overlap (como entre Londres y Nueva York).

3. \textbf{Componente de Tendencia (trend):} El tercer gr√°fico muestra una \textbf{tendencia suavizada} que sigue la direcci√≥n general del mercado. Observamos fases de \textbf{alzas y ca√≠das}: primero hay una subida clara, luego una ca√≠da, y finalmente otra leve tendencia hacia la estabilidad.

4. \textbf{Componente de Residuos o Resto (remainder):} El √∫ltimo gr√°fico (remainder) muestra los \textbf{residuos} o la parte de los datos que no es explicada por la tendencia ni la estacionalidad. Estos residuos parecen ser \textbf{ruido blanco}, con fluctuaciones alrededor de cero, lo que indica que no hay patrones significativos adicionales no capturados por los otros componentes.

\section{Prueba de Estacionariedad}\label{prueba-de-estacionariedad}

La estacionariedad es importante en el an√°lisis de series de tiempo porque indica si las propiedades estad√≠sticas de la serie (como la media y la varianza) se mantienen constantes a lo largo del tiempo. Una serie estacionaria es generalmente m√°s f√°cil de modelar y predecir.

\begin{verbatim}
## Augmented Dickey-Fuller Test 
## alternative: stationary 
##  
## Type 1: no drift no trend 
##       lag    ADF p.value
##  [1,]   0 -0.135   0.606
##  [2,]   1 -0.133   0.606
##  [3,]   2 -0.135   0.606
##  [4,]   3 -0.131   0.607
##  [5,]   4 -0.143   0.603
##  [6,]   5 -0.146   0.603
##  [7,]   6 -0.149   0.602
##  [8,]   7 -0.147   0.602
##  [9,]   8 -0.155   0.600
## [10,]   9 -0.156   0.600
## [11,]  10 -0.158   0.599
## [12,]  11 -0.174   0.594
## [13,]  12 -0.172   0.595
## [14,]  13 -0.169   0.596
## [15,]  14 -0.166   0.597
## Type 2: with drift no trend 
##       lag   ADF p.value
##  [1,]   0 -2.20   0.248
##  [2,]   1 -2.21   0.244
##  [3,]   2 -2.23   0.238
##  [4,]   3 -2.19   0.253
##  [5,]   4 -2.20   0.250
##  [6,]   5 -2.20   0.248
##  [7,]   6 -2.21   0.244
##  [8,]   7 -2.20   0.248
##  [9,]   8 -2.19   0.254
## [10,]   9 -2.18   0.257
## [11,]  10 -2.18   0.255
## [12,]  11 -2.18   0.257
## [13,]  12 -2.18   0.257
## [14,]  13 -2.16   0.263
## [15,]  14 -2.17   0.258
## Type 3: with drift and trend 
##       lag   ADF p.value
##  [1,]   0 -2.91   0.192
##  [2,]   1 -2.93   0.186
##  [3,]   2 -2.94   0.180
##  [4,]   3 -2.90   0.196
##  [5,]   4 -2.90   0.197
##  [6,]   5 -2.90   0.196
##  [7,]   6 -2.91   0.193
##  [8,]   7 -2.90   0.197
##  [9,]   8 -2.88   0.207
## [10,]   9 -2.87   0.210
## [11,]  10 -2.87   0.209
## [12,]  11 -2.85   0.219
## [13,]  12 -2.85   0.218
## [14,]  13 -2.84   0.223
## [15,]  14 -2.85   0.216
## ---- 
## Note: in fact, p.value = 0.01 means p.value <= 0.01
\end{verbatim}

\begin{verbatim}
## $type1
##       lag        ADF   p.value
##  [1,]   0 -0.1349353 0.6056581
##  [2,]   1 -0.1332845 0.6061322
##  [3,]   2 -0.1350012 0.6056392
##  [4,]   3 -0.1311022 0.6067589
##  [5,]   4 -0.1432485 0.6032707
##  [6,]   5 -0.1455745 0.6026027
##  [7,]   6 -0.1491280 0.6015823
##  [8,]   7 -0.1466525 0.6022932
##  [9,]   8 -0.1553530 0.5997946
## [10,]   9 -0.1558747 0.5996447
## [11,]  10 -0.1575228 0.5991714
## [12,]  11 -0.1743717 0.5943327
## [13,]  12 -0.1723248 0.5949206
## [14,]  13 -0.1686293 0.5959819
## [15,]  14 -0.1662663 0.5966605
## 
## $type2
##       lag       ADF   p.value
##  [1,]   0 -2.199690 0.2481241
##  [2,]   1 -2.210308 0.2438767
##  [3,]   2 -2.225752 0.2376991
##  [4,]   3 -2.186315 0.2534741
##  [5,]   4 -2.196090 0.2495641
##  [6,]   5 -2.199991 0.2480038
##  [7,]   6 -2.210932 0.2436273
##  [8,]   7 -2.199519 0.2481923
##  [9,]   8 -2.185380 0.2538481
## [10,]   9 -2.178336 0.2566657
## [11,]  10 -2.183564 0.2545744
## [12,]  11 -2.178602 0.2565592
## [13,]  12 -2.178490 0.2566041
## [14,]  13 -2.163515 0.2625942
## [15,]  14 -2.174827 0.2580694
## 
## $type3
##       lag       ADF   p.value
##  [1,]   0 -2.911720 0.1919072
##  [2,]   1 -2.925278 0.1861988
##  [3,]   2 -2.940306 0.1798712
##  [4,]   3 -2.902268 0.1958871
##  [5,]   4 -2.899542 0.1970351
##  [6,]   5 -2.901407 0.1962497
##  [7,]   6 -2.909540 0.1928254
##  [8,]   7 -2.900196 0.1967594
##  [9,]   8 -2.875536 0.2071427
## [10,]   9 -2.867569 0.2104971
## [11,]  10 -2.871608 0.2087965
## [12,]  11 -2.848029 0.2187245
## [13,]  12 -2.850350 0.2177475
## [14,]  13 -2.838511 0.2227323
## [15,]  14 -2.853430 0.2164506
\end{verbatim}

La interpretaci√≥n es la siguiente:

\begin{itemize}
\item
  \textbf{Hip√≥tesis nula (H0)}: La serie no es estacionaria (tiene una ra√≠z unitaria).
\item
  \textbf{Hip√≥tesis alternativa (H1)}: La serie es estacionaria.
\end{itemize}

En todas las configuraciones (sin tendencia ni drift, con drift, y con drift y tendencia), los p-valores son mayores a 0.05. Esto implica que, bajo ninguna de estas configuraciones, la serie es estacionaria en su forma actual.

\section{Diferenciaci√≥n para Estacionariedad}\label{diferenciaciuxf3n-para-estacionariedad}

Como la serie no es estacionaria, el siguiente paso es aplicar una diferenciaci√≥n para intentar volverla estacionaria. La diferenciaci√≥n ayuda a eliminar tendencias y hacer que las propiedades estad√≠sticas de la serie se mantengan constantes a lo largo del tiempo.

Aplicaremos una diferenciaci√≥n de primer orden y realizaremos nuevamente la prueba ADF para verificar si la serie se ha vuelto estacionaria.

Para este an√°lisis, utilizaremos la columna de cierre (\texttt{Close}) del dataset como nuestra serie de tiempo principal. Convertiremos los datos a formato de serie temporal.

Aplicaremos una primera diferenciaci√≥n.

\includegraphics{bookdown_time_series_files/figure-latex/differencing-1-1.pdf}

Despu√©s de la primera diferenciaci√≥n, se puede obtener que por cada tick qued√≥ el valor del return (x-x\_ant) ue es el resultado de la aplicaci√≥n de la dirferenciaci√≥nd e primer orden. Como se aprecia, la serie ya no tiene una tendencia sino que presenta un comportamiento estacionario, sinembargo, esta serie de tiempo parece ser menos predecible que la serie de tiempo antes de la diferenciaci√≥n, ya que evidentemente tiene mayor desviaci√≥n est√°ndar y por tanto un mayor Coeficiente de Variaci√≥n y un menor SNR.

\section{Verificaci√≥n de Estacionariedad en la Serie Diferenciada}\label{verificaciuxf3n-de-estacionariedad-en-la-serie-diferenciada}

Aplicamos nuevamente la prueba Dickey-Fuller a la serie diferenciada para verificar si ahora es estacionaria.

\begin{verbatim}
## Augmented Dickey-Fuller Test 
## alternative: stationary 
##  
## Type 1: no drift no trend 
##       lag    ADF p.value
##  [1,]   0 -169.3    0.01
##  [2,]   1 -119.0    0.01
##  [3,]   2  -99.3    0.01
##  [4,]   3  -84.8    0.01
##  [5,]   4  -75.7    0.01
##  [6,]   5  -68.7    0.01
##  [7,]   6  -64.1    0.01
##  [8,]   7  -60.1    0.01
##  [9,]   8  -56.8    0.01
## [10,]   9  -53.7    0.01
## [11,]  10  -50.9    0.01
## [12,]  11  -48.8    0.01
## [13,]  12  -47.3    0.01
## [14,]  13  -45.4    0.01
## [15,]  14  -43.7    0.01
## Type 2: with drift no trend 
##       lag    ADF p.value
##  [1,]   0 -169.3    0.01
##  [2,]   1 -119.0    0.01
##  [3,]   2  -99.3    0.01
##  [4,]   3  -84.8    0.01
##  [5,]   4  -75.7    0.01
##  [6,]   5  -68.7    0.01
##  [7,]   6  -64.1    0.01
##  [8,]   7  -60.1    0.01
##  [9,]   8  -56.8    0.01
## [10,]   9  -53.7    0.01
## [11,]  10  -50.9    0.01
## [12,]  11  -48.8    0.01
## [13,]  12  -47.3    0.01
## [14,]  13  -45.4    0.01
## [15,]  14  -43.7    0.01
## Type 3: with drift and trend 
##       lag    ADF p.value
##  [1,]   0 -169.3    0.01
##  [2,]   1 -119.0    0.01
##  [3,]   2  -99.3    0.01
##  [4,]   3  -84.9    0.01
##  [5,]   4  -75.7    0.01
##  [6,]   5  -68.7    0.01
##  [7,]   6  -64.1    0.01
##  [8,]   7  -60.1    0.01
##  [9,]   8  -56.8    0.01
## [10,]   9  -53.7    0.01
## [11,]  10  -50.9    0.01
## [12,]  11  -48.8    0.01
## [13,]  12  -47.3    0.01
## [14,]  13  -45.4    0.01
## [15,]  14  -43.7    0.01
## ---- 
## Note: in fact, p.value = 0.01 means p.value <= 0.01
\end{verbatim}

\begin{verbatim}
## $type1
##       lag        ADF p.value
##  [1,]   0 -169.27722    0.01
##  [2,]   1 -119.03874    0.01
##  [3,]   2  -99.30334    0.01
##  [4,]   3  -84.84969    0.01
##  [5,]   4  -75.69590    0.01
##  [6,]   5  -68.70703    0.01
##  [7,]   6  -64.07591    0.01
##  [8,]   7  -60.05652    0.01
##  [9,]   8  -56.77621    0.01
## [10,]   9  -53.68723    0.01
## [11,]  10  -50.91061    0.01
## [12,]  11  -48.81278    0.01
## [13,]  12  -47.29027    0.01
## [14,]  13  -45.38630    0.01
## [15,]  14  -43.68676    0.01
## 
## $type2
##       lag        ADF p.value
##  [1,]   0 -169.27433    0.01
##  [2,]   1 -119.03671    0.01
##  [3,]   2  -99.30166    0.01
##  [4,]   3  -84.84825    0.01
##  [5,]   4  -75.69462    0.01
##  [6,]   5  -68.70587    0.01
##  [7,]   6  -64.07484    0.01
##  [8,]   7  -60.05550    0.01
##  [9,]   8  -56.77525    0.01
## [10,]   9  -53.68632    0.01
## [11,]  10  -50.90973    0.01
## [12,]  11  -48.81194    0.01
## [13,]  12  -47.28946    0.01
## [14,]  13  -45.38553    0.01
## [15,]  14  -43.68601    0.01
## 
## $type3
##       lag        ADF p.value
##  [1,]   0 -169.27489    0.01
##  [2,]   1 -119.03832    0.01
##  [3,]   2  -99.30402    0.01
##  [4,]   3  -84.85094    0.01
##  [5,]   4  -75.69772    0.01
##  [6,]   5  -68.70929    0.01
##  [7,]   6  -64.07866    0.01
##  [8,]   7  -60.05942    0.01
##  [9,]   8  -56.77944    0.01
## [10,]   9  -53.69075    0.01
## [11,]  10  -50.91391    0.01
## [12,]  11  -48.81642    0.01
## [13,]  12  -47.29426    0.01
## [14,]  13  -45.39063    0.01
## [15,]  14  -43.69120    0.01
\end{verbatim}

\section{Justificaci√≥n de la Transformaci√≥n}\label{justificaciuxf3n-de-la-transformaciuxf3n}

Dado que la serie original no era estacionaria, fue necesario aplicar una diferenciaci√≥n de primer orden para hacerla estacionaria. Esta transformaci√≥n es importante para poder aplicar modelos de series de tiempo que asumen estacionariedad y para obtener mejores resultados en el an√°lisis de patrones y predicciones.

\section{An√°lisis de Autocorrelaci√≥n}\label{anuxe1lisis-de-autocorrelaciuxf3n}

Graficaremos las funciones de autocorrelaci√≥n (ACF) y autocorrelaci√≥n parcial (PACF) para observar la dependencia temporal en los datos diferenciados.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Graficar ACF y PACF de la serie diferenciada}
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow =} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{))}
\FunctionTok{Acf}\NormalTok{(forex\_diff, }\AttributeTok{main =} \StringTok{"ACF de la Serie Diferenciada"}\NormalTok{)}
\FunctionTok{Pacf}\NormalTok{(forex\_diff, }\AttributeTok{main =} \StringTok{"PACF de la Serie Diferenciada"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{bookdown_time_series_files/figure-latex/acf-pacf-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow =} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

La ACF a la izquierda muestra c√≥mo los valores actuales de la serie diferenciada est√°n correlacionados con sus valores en diferentes rezagos (lags). Algunos puntos de la ACF est√°n fuera de las l√≠neas de significancia (l√≠neas punteadas azules), lo cual sugiere que hay correlaciones significativas en esos rezagos espec√≠ficos. Este patr√≥n puede ser indicativo de que a√∫n existen estructuras autoregresivas o de medias m√≥viles en la serie, incluso despu√©s de la diferenciaci√≥n.

La PACF a la derecha muestra la autocorrelaci√≥n de la serie diferenciada en cada rezago eliminando el efecto de los rezagos intermedios. Similar a la ACF, algunos valores est√°n fuera de las l√≠neas de significancia, lo que indica correlaci√≥n significativa en esos rezagos espec√≠ficos. Este patr√≥n puede sugerir la presencia de efectos autoregresivos en los rezagos correspondientes.

Los picos significativos en la ACF y PACF sugieren que la serie diferenciada podr√≠a beneficiarse de un modelo ARIMA para capturar la estructura subyacente. Dependiendo de la cantidad de rezagos significativos en cada gr√°fico, podr√≠a ser apropiado un modelo ARIMA espec√≠fico (por ejemplo, con ciertos √≥rdenes autoregresivos y de medias m√≥viles).

\section{Modelo ARIMA}\label{modelo-arima}

Utilizaremos \texttt{auto.arima} para identificar el mejor modelo ARIMA para los datos.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Ajuste del modelo ARIMA}
\NormalTok{forex\_arima }\OtherTok{\textless{}{-}} \FunctionTok{auto.arima}\NormalTok{(forex\_diff)}
\FunctionTok{summary}\NormalTok{(forex\_arima)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Series: forex_diff 
## ARIMA(0,0,0) with zero mean 
## 
## sigma^2 = 8.978e-06:  log likelihood = 126732.8
## AIC=-253463.6   AICc=-253463.6   BIC=-253455.4
## 
## Training set error measures:
##                        ME        RMSE         MAE MPE MAPE     MASE        ACF1
## Training set 1.304966e-06 0.002996269 0.001979825 100  100 0.675058 0.003518741
\end{verbatim}

El modelo ajustado para la serie forex\_diff es un ARIMA(0,0,0) con media cero, lo que sugiere que la serie no presenta patrones autoregresivos ni de medias m√≥viles significativos, siendo esencialmente ruido blanco. El valor de sigma\^{}2 = 8.978√ó10 ‚àí6 representa la varianza del error, con una alta verosimilitud (log likelihood) de 126732.8. Los criterios de informaci√≥n, AIC y BIC, son de -253463.6 y -253455.4, respectivamente, indicando un buen ajuste para este modelo sencillo. Las medidas de error en el conjunto de entrenamiento muestran un error medio (ME) cercano a cero (1.30e-06) y un RMSE de 0.002996, lo cual refleja una precisi√≥n razonable. La autocorrelaci√≥n en el primer rezago (ACF1) es baja (0.0035), sugiriendo independencia en los residuos.

\section{Detecci√≥n de Puntos de Cambio}\label{detecciuxf3n-de-puntos-de-cambio}

Usaremos la funci√≥n \texttt{cpt.mean} para detectar cambios significativos en la media de la serie.

\includegraphics{bookdown_time_series_files/figure-latex/change-point-1.pdf}

No se detectaron puntos de cambio, debido a que despu√©s de la diferenciaci√≥n, se convierte b√°sicamente en ruido blanco.

\section{Media Cero de los Residuos}\label{media-cero-de-los-residuos}

Comprobamos si la media de los residuos es cero.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Prueba t en los residuos}
\NormalTok{residuals\_arima }\OtherTok{\textless{}{-}} \FunctionTok{residuals}\NormalTok{(forex\_arima)}
\NormalTok{t\_test\_residuals }\OtherTok{\textless{}{-}} \FunctionTok{t.test}\NormalTok{(residuals\_arima)}
\FunctionTok{print}\NormalTok{(t\_test\_residuals)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##  One Sample t-test
## 
## data:  residuals_arima
## t = 0.073986, df = 28858, p-value = 0.941
## alternative hypothesis: true mean is not equal to 0
## 95 percent confidence interval:
##  -3.326619e-05  3.587612e-05
## sample estimates:
##    mean of x 
## 1.304966e-06
\end{verbatim}

La prueba t de una muestra realizada sobre los residuos (residuals\_arima) arroja un valor de ùë°=0.073986 con 28,858 grados de libertad y un valor p de 0.941. Dado que el valor p es significativamente mayor a 0.05, no rechazamos la hip√≥tesis nula de que la media de los residuos es igual a cero. Esto sugiere que los residuos no presentan un sesgo significativo. El intervalo de confianza del 95\% para la media de los residuos y la media estimada muy cercana a cero es consistente con un modelo bien ajustado sin tendencia sistem√°tica en los errores.

\section{Independencia de los Residuos}\label{independencia-de-los-residuos}

Evaluamos la independencia de los residuos usando la prueba de Ljung-Box.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Prueba de independencia}
\FunctionTok{Box.test}\NormalTok{(residuals\_arima, }\AttributeTok{lag =} \DecValTok{20}\NormalTok{, }\AttributeTok{type =} \StringTok{"Ljung{-}Box"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##  Box-Ljung test
## 
## data:  residuals_arima
## X-squared = 30.772, df = 20, p-value = 0.05827
\end{verbatim}

Los datos cargados contienen 28,860 filas y 6 columnas de informaci√≥n sobre el tipo de cambio EUR/USD. La prueba de Dickey-Fuller Aumentada (ADF) realizada en tres configuraciones (sin constante ni tendencia, con constante sin tendencia, y con constante y tendencia) muestra valores ADF altamente negativos y p-valores menores o iguales a 0.01, lo que indica que la serie diferenciada es estacionaria. Adem√°s, la prueba de Box-Ljung aplicada a los residuos del modelo ARIMA arroja un valor de 30.772 con un valor p de 0.05827, lo cual sugiere que los residuos \textbf{no tienen autocorrelaci√≥n significativa}, indicando independencia en los errores del modelo.

\section{Distribuci√≥n de los Residuos}\label{distribuciuxf3n-de-los-residuos}

Analizaremos la normalidad de los residuos con un gr√°fico Q-Q.

\includegraphics{bookdown_time_series_files/figure-latex/residuals-qqplot-1.pdf}

El gr√°fico Q-Q muestra que los residuos del modelo se alinean con la normalidad en el centro de la distribuci√≥n, pero presentan desviaciones significativas en las colas. Esto sugiere que, aunque los residuos se comportan aproximadamente como una distribuci√≥n normal en el centro, tienen colas m√°s pesadas de lo esperado, lo que indica la presencia de valores extremos.

\chapter{An√°lisis de Series de Tiempo con el M√©todo Holt-Winters}\label{anuxe1lisis-de-series-de-tiempo-con-el-muxe9todo-holt-winters}

Este documento realiza un an√°lisis de series de tiempo utilizando el m√©todo de Holt-Winters aplicado exclusivamente a la columna \texttt{close} del dataset \texttt{EURUSD\_ForexTrading\_4hrs.csv}. Se utilizar√°n solo 6000 datos, normalizando la columna \texttt{close}, dividiendo en conjunto de entrenamiento y prueba, y calculando la m√©tricas de error MAE en el conjunto de entrenamiento y en el conjunto de prueba.

\section{Carga de Bibliotecas y Datos}\label{carga-de-bibliotecas-y-datos}

\begin{table}
\centering
\caption{\label{tab:cargar-datos}Primeras filas del dataset EURUSD ForexTrading 4hrs Columna close}
\centering
\begin{tabular}[t]{r}
\hline
close\\
\hline
1.12274\\
\hline
1.12126\\
\hline
1.12113\\
\hline
1.12174\\
\hline
1.12712\\
\hline
1.12804\\
\hline
\end{tabular}
\end{table}

El dataset \texttt{EURUSD\_ForexTrading\_4hrs.csv} contiene datos de trading del par de divisas EUR/USD con una frecuencia de 4 horas. Solo se ha seleccionado la columna \texttt{close} con los primeros 6000 datos para este an√°lisis.

\section{Normalizaci√≥n de la Columna `close'}\label{normalizaciuxf3n-de-la-columna-close}

\begin{table}
\centering
\caption{\label{tab:normalizar-close}Columna 'close' Normalizada}
\centering
\begin{tabular}[t]{r}
\hline
x\\
\hline
0.1566893\\
\hline
0.1515141\\
\hline
0.1510595\\
\hline
0.1531925\\
\hline
0.1720050\\
\hline
0.1752220\\
\hline
\end{tabular}
\end{table}

Se ha normalizado la columna \texttt{close} utilizando la t√©cnica Min-Max, transformando los valores entre 0 y 1 para mejorar la estabilidad del modelo.

\section{Descomposici√≥n Estacional}\label{descomposiciuxf3n-estacional}

\includegraphics{bookdown_time_series_files/figure-latex/descomposicion-estacional-1.png}

Descomponemos la serie temporal en componentes de tendencia, estacionalidad y ruido para analizar los patrones internos de la serie temporal antes de aplicar el modelo.

\section{Suavizado Exponencial Simple}\label{suavizado-exponencial-simple}

\includegraphics{bookdown_time_series_files/figure-latex/suavizado-simple-1.png}

Aplicamos el suavizado exponencial simple a la serie \texttt{close} para visualizar una versi√≥n suavizada de la serie de tiempo. Se pude observar como la se√±al original contiene mas ruido que la suavizada.

\section{Suavizado Exponencial Doble (Aditivo y Multiplicativo)}\label{suavizado-exponencial-doble-aditivo-y-multiplicativo}

\includegraphics{bookdown_time_series_files/figure-latex/suavizado-doble-1.png}

Se puede apreciar que tanto el suavizado aditivo como el multiplicativo producen una estimaci√≥n cercana a los datos originales, aunque estas se√±ales contienen mas ruido que el suavizado simple e incluso al parecer mas que la se√±al original.

\section{Calculo de error}\label{calculo-de-error}

Se calcularon los errores de los modelos multiplicativo y aditivo en el dataset de training. Se usa un ajuste de 0.001 para el modelo multiplicativo, porque este requiere que todos los datos sean positivos y mayores que cero (no admite ceros), y como los datos fueron nomalizados con min-max, obligatoriamente existe al menos un valor de cero.

\begin{verbatim}
## MAE en entrenamiento (Aditivo): 0.01972768
\end{verbatim}

\begin{verbatim}
## MAE en entrenamiento (Multiplicativo): 0.05277391
\end{verbatim}

Finalmente se calcularon los errores de los modelos en el dataset de validaci√≥n

\begin{verbatim}
## MAE en validaci√≥n (Aditivo): 2.350168
\end{verbatim}

\begin{verbatim}
## MAE en validaci√≥n (Multiplicativo): 4.704901
\end{verbatim}

Este gigantesco error es debido a que el modelo trata de predecir todo el dataset de validaci√≥n de una sola vez (1238 ticks). En otros modelos predictivos en series de tiempo como redes neuronales, se usa un sliding window usando los √∫ltimos 128 ticks como entrada del modelo, se predice el siguiente, y esto se repite para cada tick, luego se promedian todos los errores y esa es la medida de desempe√±o de la red neuronal.

Para poder comparar el desempe√±o predictivo del modelo Holt-Winter con otros modelos predictivos en una serie de tiempo larga como la nuestra, probablemente se requiera usar sliding window como en las redes neuronales, se requerir√≠a adaptar el modelo Holt-Winter para que se entrene con una ventana y prediga segmentos cortos que se concatenan y que formar√≠an la se√±al pronosticada, con la cual se calcular√≠an y promediar√≠an los errores por tick, en lugar de tratar de predecir la serie de tiempo completa de una sola vez.

\section{Conclusiones}\label{conclusiones}

El m√©todo Holt-Winters aplicado a la columna \texttt{close} del conjunto de datos muestra que este modelo es capaz de capturar patrones de tendencia y estacionalidad en los datos de precios de cierre normalizados. Las m√©tricas de evaluaci√≥n como MAE muestran la precisi√≥n del modelo tanto en el conjunto de entrenamiento como en el conjunto de prueba, donde se puede apreciar que la predicci√≥n de todo el dataset de validaci√≥n completo no es una buena forma de evaluar el desempe√±o de estos modelos, especialmente para comaprarlos con modelos ampliamente usados como las redes neuronales.

\chapter{Modelos Estacionarios}\label{modelos-estacionarios}

En esta secci√≥n, analizamos y predecimos series temporales usando la metodolog√≠a \textbf{Box-Jenkins}. El objetivo es ajustar modelos autoregresivos integrados de media m√≥vil (ARIMA) para encontrar patrones subyacentes en los datos y realizar predicciones futuras.

El dataset analizado contiene precios Forex EUR/USD en intervalos de 4 horas, el cual ser√° procesado y transformado para cumplir con los requisitos de estacionariedad y ajuste de modelos ARIMA.

\section{Objetivo}\label{objetivo}

Esquematizar los modelos convencionales de series temporales mediante la metodolog√≠a \textbf{Box-Jenkins} y explorar su aplicabilidad en la predicci√≥n de futuras observaciones.

\section{1. Carga y Exploraci√≥n de los Datos}\label{carga-y-exploraciuxf3n-de-los-datos}

En esta secci√≥n se carga el dataset \texttt{EURUSD\_ForexTrading\_4hrs.csv}, y se realiza una exploraci√≥n inicial para entender su estructura y caracter√≠sticas b√°sicas.

\begin{verbatim}
##                  Gmt.time    open    high     low   close   volume
## 1 04.05.2003 21:00:00.000 1.12354 1.12354 1.12166 1.12274  95533.1
## 2 05.05.2003 01:00:00.000 1.12242 1.12276 1.12067 1.12126  93778.6
## 3 05.05.2003 05:00:00.000 1.12139 1.12255 1.12030 1.12113  90924.7
## 4 05.05.2003 09:00:00.000 1.12092 1.12331 1.12049 1.12174  91254.7
## 5 05.05.2003 13:00:00.000 1.12194 1.12900 1.12130 1.12712 308003.4
## 6 05.05.2003 17:00:00.000 1.12718 1.13019 1.12657 1.12804 373668.3
\end{verbatim}

\begin{verbatim}
##    Gmt.time              open            high            low       
##  Length:28860       Min.   :1.037   Min.   :1.039   Min.   :1.034  
##  Class :character   1st Qu.:1.154   1st Qu.:1.156   1st Qu.:1.152  
##  Mode  :character   Median :1.242   Median :1.244   Median :1.240  
##                     Mean   :1.254   Mean   :1.256   Mean   :1.252  
##                     3rd Qu.:1.339   3rd Qu.:1.341   3rd Qu.:1.337  
##                     Max.   :1.599   Max.   :1.604   Max.   :1.597  
##      close           volume      
##  Min.   :1.037   Min.   :     0  
##  1st Qu.:1.154   1st Qu.: 20322  
##  Median :1.242   Median : 47813  
##  Mean   :1.254   Mean   : 83079  
##  3rd Qu.:1.339   3rd Qu.:102455  
##  Max.   :1.599   Max.   :752269
\end{verbatim}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{2. Limpieza y Preprocesamiento de los Datos}\label{limpieza-y-preprocesamiento-de-los-datos}

Se seleccionan las columnas relevantes (en este caso, \texttt{Close}) y se convierten en una serie temporal.

\includegraphics{bookdown_time_series_files/figure-latex/clean-data-1.pdf}

El gr√°fico representa la serie temporal original del precio de cierre del par Forex EUR/USD, registrado en intervalos de 4 horas. Observamos fluctuaciones significativas que reflejan los cambios en el mercado durante el per√≠odo analizado. La serie muestra patrones evidentes de tendencias ascendentes y descendentes, lo que sugiere posibles componentes de largo plazo y estacionalidad que deben ser tratados en etapas posteriores del an√°lisis, como la transformaci√≥n a estacionariedad y la descomposici√≥n de los datos.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{3. Divisi√≥n del Dataset en Conjuntos de Entrenamiento y Validaci√≥n}\label{divisiuxf3n-del-dataset-en-conjuntos-de-entrenamiento-y-validaciuxf3n}

Se divide el dataset en 70\% para entrenamiento y 30\% para evaluaci√≥n del modelo.

\section{4. Normalizaci√≥n de los Datos}\label{normalizaciuxf3n-de-los-datos}

La normalizaci√≥n es √∫til para estabilizar la varianza y hacer que los datos sean m√°s adecuados para el an√°lisis.

\includegraphics{bookdown_time_series_files/figure-latex/normalize-data-1.pdf}

Como se observa, el rango de los datos ahora se encuentra entre 0 y 1.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{5. Verificaci√≥n de Estacionariedad}\label{verificaciuxf3n-de-estacionariedad}

La serie debe ser estacionaria para que los modelos ARIMA sean v√°lidos. Evaluamos esto usando la prueba Dickey-Fuller Aumentada (ADF).

\begin{verbatim}
## Augmented Dickey-Fuller Test 
## alternative: stationary 
##  
## Type 1: no drift no trend 
##       lag    ADF p.value
##  [1,]   0 -0.861   0.372
##  [2,]   1 -0.868   0.369
##  [3,]   2 -0.874   0.367
##  [4,]   3 -0.861   0.372
##  [5,]   4 -0.874   0.367
##  [6,]   5 -0.876   0.366
##  [7,]   6 -0.878   0.365
##  [8,]   7 -0.874   0.367
##  [9,]   8 -0.875   0.367
## [10,]   9 -0.873   0.367
## [11,]  10 -0.877   0.366
## [12,]  11 -0.886   0.363
## [13,]  12 -0.885   0.363
## [14,]  13 -0.876   0.366
## Type 2: with drift no trend 
##       lag   ADF p.value
##  [1,]   0 -2.12   0.278
##  [2,]   1 -2.15   0.268
##  [3,]   2 -2.17   0.261
##  [4,]   3 -2.13   0.276
##  [5,]   4 -2.14   0.273
##  [6,]   5 -2.14   0.272
##  [7,]   6 -2.14   0.272
##  [8,]   7 -2.13   0.275
##  [9,]   8 -2.11   0.285
## [10,]   9 -2.10   0.287
## [11,]  10 -2.11   0.285
## [12,]  11 -2.09   0.292
## [13,]  12 -2.09   0.291
## [14,]  13 -2.08   0.298
## Type 3: with drift and trend 
##       lag   ADF p.value
##  [1,]   0 -2.16   0.507
##  [2,]   1 -2.19   0.496
##  [3,]   2 -2.21   0.489
##  [4,]   3 -2.17   0.505
##  [5,]   4 -2.18   0.501
##  [6,]   5 -2.18   0.501
##  [7,]   6 -2.18   0.501
##  [8,]   7 -2.17   0.504
##  [9,]   8 -2.15   0.514
## [10,]   9 -2.14   0.517
## [11,]  10 -2.15   0.514
## [12,]  11 -2.13   0.523
## [13,]  12 -2.13   0.521
## [14,]  13 -2.11   0.528
## ---- 
## Note: in fact, p.value = 0.01 means p.value <= 0.01
\end{verbatim}

\begin{verbatim}
## $type1
##       lag        ADF   p.value
##  [1,]   0 -0.8607895 0.3716268
##  [2,]   1 -0.8679287 0.3690726
##  [3,]   2 -0.8742777 0.3668010
##  [4,]   3 -0.8606220 0.3716867
##  [5,]   4 -0.8741001 0.3668646
##  [6,]   5 -0.8764373 0.3660284
##  [7,]   6 -0.8781312 0.3654224
##  [8,]   7 -0.8743629 0.3667706
##  [9,]   8 -0.8746145 0.3666806
## [10,]   9 -0.8733773 0.3671232
## [11,]  10 -0.8765659 0.3659824
## [12,]  11 -0.8856760 0.3627230
## [13,]  12 -0.8848509 0.3630182
## [14,]  13 -0.8762256 0.3661041
## 
## $type2
##       lag       ADF   p.value
##  [1,]   0 -2.124490 0.2782040
##  [2,]   1 -2.149853 0.2680589
##  [3,]   2 -2.166670 0.2613321
##  [4,]   3 -2.129695 0.2761221
##  [5,]   4 -2.138047 0.2727812
##  [6,]   5 -2.140018 0.2719927
##  [7,]   6 -2.139519 0.2721925
##  [8,]   7 -2.132869 0.2748525
##  [9,]   8 -2.108596 0.2845615
## [10,]   9 -2.102436 0.2870256
## [11,]  10 -2.108329 0.2846684
## [12,]  11 -2.089681 0.2921277
## [13,]  12 -2.093017 0.2907933
## [14,]  13 -2.075880 0.2976481
## 
## $type3
##       lag       ADF   p.value
##  [1,]   0 -2.164022 0.5068136
##  [2,]   1 -2.189210 0.4961222
##  [3,]   2 -2.205776 0.4891471
##  [4,]   3 -2.169354 0.5045398
##  [5,]   4 -2.176674 0.5014184
##  [6,]   5 -2.178475 0.5006505
##  [7,]   6 -2.177817 0.5009308
##  [8,]   7 -2.171376 0.5036774
##  [9,]   8 -2.146670 0.5142130
## [10,]   9 -2.140507 0.5168410
## [11,]  10 -2.146217 0.5144060
## [12,]  11 -2.126486 0.5228201
## [13,]  12 -2.129930 0.5213512
## [14,]  13 -2.113231 0.5284725
\end{verbatim}

El resultado de la prueba Dickey-Fuller Aumentada (ADF) muestra un estad√≠stico Dickey-Fuller de -2.0393 con un p-valor de 0.5618, lo que indica que no podemos rechazar la hip√≥tesis nula de que la serie tiene una ra√≠z unitaria. Esto significa que la serie norm\_train\_data no es estacionaria. Dado que la estacionariedad es un requisito fundamental para ajustar modelos ARIMA, ser√° necesario transformar la serie, aplicando una diferenciaci√≥n para estabilizar su media y eliminar tendencias.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{6. Transformaci√≥n a Estacionariedad}\label{transformaciuxf3n-a-estacionariedad}

Si la serie no es estacionaria, aplicamos una diferenciaci√≥n para eliminar tendencias no deseadas.

\includegraphics{bookdown_time_series_files/figure-latex/differencing-2-1.pdf}

El gr√°fico muestra la serie diferenciada con valores oscilando alrededor de 0, entre aproximadamente -0.02 y 0.02. Esto indica que la diferenciaci√≥n logr√≥ estabilizar la media y eliminar tendencias, dejando la serie preparada para verificar su estacionariedad y ajustar un modelo ARIMA.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{7. An√°lisis ACF y PACF}\label{anuxe1lisis-acf-y-pacf}

Los gr√°ficos de ACF y PACF ayudan a determinar los valores \(p\) y \(q\) del modelo ARIMA.

\includegraphics{bookdown_time_series_files/figure-latex/identify-parameters-1.pdf}

El gr√°fico de la ACF (Funci√≥n de Autocorrelaci√≥n) muestra un primer retardo significativo, con un valor cercano a 1.0, mientras que los retardos restantes est√°n dentro de los intervalos de confianza (¬±0.05), indicando que no hay correlaci√≥n significativa m√°s all√° del primer lag.

\includegraphics{bookdown_time_series_files/figure-latex/identify-parameters-2-1.pdf}

En el gr√°fico de la PACF (Funci√≥n de Autocorrelaci√≥n Parcial), los primeros retardos presentan valores significativos positivos y negativos, especialmente en los primeros lags, como el 1, 3 y 5. Esto sugiere la posible inclusi√≥n de t√©rminos autorregresivos (AR) en el modelo ARIMA.

Estos resultados gu√≠an la selecci√≥n de los par√°metros para ajustar un modelo ARIMA adecuado.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{8. Ajuste del Modelo ARIMA}\label{ajuste-del-modelo-arima}

Ajustamos un modelo ARIMA utilizando los valores \(p\), \(d\) y \(q\) obtenidos previamente. Usamos \texttt{auto.arima} para seleccionar autom√°ticamente los mejores par√°metros.

\begin{verbatim}
## Series: norm_train_data 
## ARIMA(4,1,0) 
## 
## Coefficients:
##          ar1     ar2      ar3     ar4
##       0.0095  0.0075  -0.0163  0.0121
## s.e.  0.0070  0.0070   0.0070  0.0070
## 
## sigma^2 = 3.647e-05:  log likelihood = 74553.92
## AIC=-149097.8   AICc=-149097.8   BIC=-149058.3
## 
## Training set error measures:
##                         ME        RMSE         MAE  MPE MAPE     MASE
## Training set -2.667179e-07 0.006038687 0.004067731 -Inf  Inf 1.000317
##                       ACF1
## Training set -2.599614e-05
\end{verbatim}

El modelo ajustado sobre la serie normalizada (\textbf{norm\_train\_data}) es un \textbf{ARIMA(4,1,0)} con los siguientes coeficientes: - \textbf{AR1}: 0.0095 (s.e.: 0.0070), - \textbf{AR2}: 0.0075 (s.e.: 0.0070), - \textbf{AR3}: -0.0163 (s.e.: 0.0070), - \textbf{AR4}: 0.0121 (s.e.: 0.0070).

Indicadores del modelo: - \textbf{Log-Likelihood}: 74553.92, - \textbf{AIC}: -149097.8, - \textbf{BIC}: -149058.3.

M√©tricas del conjunto de entrenamiento: - \textbf{RMSE}: 0.0060, - \textbf{MAE}: 0.0041, - \textbf{ACF1}: -0.000026.

Estos resultados indican un ajuste razonable del modelo a los datos normalizados, con residuos independientes y m√©tricas de error bajas en el conjunto de entrenamiento. Sin embargo, la presencia de valores extremos en las m√©tricas como MAPE y MPE (\(-\infty, \infty\)) sugiere posibles problemas en los c√°lculos debido a la normalizaci√≥n o a valores cercanos a cero.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{9. Validaci√≥n del Modelo}\label{validaciuxf3n-del-modelo}

Se validan los supuestos del modelo mediante el an√°lisis de los residuos.

\includegraphics{bookdown_time_series_files/figure-latex/validate-model-1-1.pdf}

\begin{verbatim}
## 
##  Ljung-Box test
## 
## data:  Residuals from ARIMA(4,1,0)
## Q* = 0.91976, df = 6, p-value = 0.9885
## 
## Model df: 4.   Total lags used: 10
\end{verbatim}

El an√°lisis de los residuos del modelo \textbf{ARIMA(4,1,0)} muestra lo siguiente:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Gr√°fico de Residuos}: Los residuos oscilan alrededor de 0, con valores en el rango de aproximadamente -0.02 a 0.02, sin patrones visibles ni tendencias evidentes, lo que sugiere independencia de los residuos.
\item
  \textbf{ACF de Residuos}: Los valores de autocorrelaci√≥n de los residuos est√°n mayoritariamente dentro de los intervalos de confianza (¬±0.02), excepto por algunos picos en retardos altos, indicando que los residuos son casi ruido blanco.
\item
  \textbf{Distribuci√≥n de Residuos}: El histograma muestra una distribuci√≥n aproximadamente normal centrada en 0, corroborada por la curva de densidad ajustada, lo que valida la suposici√≥n de normalidad en los residuos.
\end{enumerate}

Estos resultados indican que el modelo ajustado cumple los supuestos de independencia y normalidad de los residuos, validando su uso para predicci√≥n.

\begin{verbatim}
## 
##  Box-Ljung test
## 
## data:  model$residuals
## X-squared = 0.91976, df = 10, p-value = 0.9999
\end{verbatim}

El resultado de la prueba \textbf{Box-Ljung} para los residuos del modelo muestra un estad√≠stico \(X^2 = 0.91976\) con \(df = 10\) grados de libertad y un \(p\text{-valor} = 0.9999\). Dado que el \(p\text{-valor} \gg 0.05\), no se puede rechazar la hip√≥tesis nula de que los residuos son ruido blanco, confirmando la independencia de los residuos y validando el ajuste del modelo.

Dado que el \(p\text{-valor} > 0.05\), no se puede rechazar la hip√≥tesis nula de que los residuos son ruido blanco. Esto confirma que los residuos del modelo no presentan autocorrelaci√≥n significativa, validando as√≠ el ajuste del modelo ARIMA.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{10. Predicci√≥n}\label{predicciuxf3n}

Realizamos predicciones para los pr√≥ximos intervalos usando el modelo ajustado.

\includegraphics{bookdown_time_series_files/figure-latex/forecast-1.pdf}

El gr√°fico muestra la serie temporal original superpuesta con la predicci√≥n generada por el modelo \textbf{ARIMA(4,1,0)}. Aunque las predicciones siguen la tendencia general de la serie, el resultado es muy similar al original debido a que el modelo representa una diferenciaci√≥n de primer orden, capturando √∫nicamente cambios incrementales sin agregar t√©rminos de media m√≥vil (\(q\)) y usando 4 para el autorregresivo.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{11. Evaluaci√≥n de Predicciones}\label{evaluaciuxf3n-de-predicciones}

Se eval√∫an las predicciones contra los datos de prueba usando m√©tricas de error.

\begin{verbatim}
## MAE en el conjunto de entrenamiento: 0.004067731
\end{verbatim}

\begin{verbatim}
## MAE en el conjunto de prueba: 0.07728354
\end{verbatim}

El error absoluto medio (MAE) del modelo en el conjunto de entrenamiento es \textbf{0.00406}, mientras que en el conjunto de prueba es significativamente mayor, con un valor de \textbf{0.0772}. Esto sugiere que el modelo se ajusta bien a los datos de entrenamiento, pero tiene dificultades para generalizar a datos no vistos, indicando un posible sobreajuste o la necesidad de mejorar la capacidad predictiva del modelo.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{12. Conclusiones}\label{conclusiones-1}

Las siguientes son las conlusiones de las actividares realizadas:

\begin{itemize}
\tightlist
\item
  \textbf{Ajuste del Modelo ARIMA}:

  \begin{itemize}
  \tightlist
  \item
    Un modelo \textbf{ARIMA(4,1,0)}, incorpor√≥ t√©rminos autorregresivos (\(p = 4\)) y mostr√≥ mejoras sutiles respecto al ARIMA(0,1,0) probado inicialmente en los indicadores como \textbf{log-likelihood = 74553.92} y \textbf{AIC = -149097.8}, con residuos que cumplen las suposiciones de ruido blanco y normalidad.
  \end{itemize}
\item
  \textbf{Validaci√≥n del Modelo}:

  \begin{itemize}
  \tightlist
  \item
    La prueba \textbf{Box-Ljung} confirm√≥ que los residuos del modelo \textbf{ARIMA(4,1,0)} son independientes y no presentan autocorrelaci√≥n significativa (\(p\text{-valor} = 0.9999\)).
  \item
    Los residuos mostraron una distribuci√≥n aproximadamente normal, validando a√∫n m√°s la calidad del modelo ajustado.
  \end{itemize}
\item
  \textbf{Evaluaci√≥n de Predicciones}:

  \begin{itemize}
  \tightlist
  \item
    El \textbf{MAE en el conjunto de entrenamiento} fue de \textbf{0.00406}, mientras que en el conjunto de prueba aument√≥ significativamente a \textbf{0.07728354}, lo que indica que el modelo tiene dificultades para generalizar a datos no vistos, posiblemente debido a sobreajuste o caracter√≠sticas complejas no capturadas.
  \end{itemize}
\item
  \textbf{Limitaciones y Mejoras}:

  \begin{itemize}
  \tightlist
  \item
    Aunque el modelo \textbf{ARIMA(4,1,0)} ofrece un mejor ajuste que el \textbf{ARIMA(0,1,0)}, no logra reducir el error en el conjunto de prueba de forma significativa.
  \item
    Ser√≠a recomendable explorar modelos m√°s avanzados, como \textbf{SARIMA}, para capturar componentes estacionales, o incluir variables ex√≥genas para mejorar las predicciones.
  \end{itemize}
\end{itemize}

El uso de la metodolog√≠a \textbf{Box-Jenkins} permiti√≥ identificar patrones y ajustar modelos que explican las caracter√≠sticas principales de la serie temporal. Sin embargo, la discrepancia entre el desempe√±o en los conjuntos de entrenamiento y prueba resalta la necesidad de modelos m√°s robustos para mejorar la capacidad predictiva.

  \bibliography{book.bib,packages.bib}

\end{document}
